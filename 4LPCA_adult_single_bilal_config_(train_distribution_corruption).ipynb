{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NG\n",
    "import time\n",
    "import pulp as p \n",
    "def min_sum_lpca(data1,beta,eps,e,alpha):\n",
    "    import pulp as p \n",
    "    import math\n",
    "    #for bilal\n",
    "    #beta=[beta1[1], beta1[0],beta1[6],beta1[4],beta1[3],beta1[2],beta1[5]]\n",
    "    #print(beta)\n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    \n",
    "    ################ sorted result\n",
    "    a1=0\n",
    "    a2=0\n",
    "    b1=0\n",
    "    b2=0\n",
    "    c1=0\n",
    "    c2=0\n",
    "    d1=0\n",
    "    d2=0\n",
    "    e1=0\n",
    "    e2=0\n",
    "    h1=[]\n",
    "    h2=[]\n",
    "    h3=[]\n",
    "    h4=[]\n",
    "    h5=[]\n",
    "    h6=[]\n",
    "    h7=[]\n",
    "    key1=[]\n",
    "    key2=[]\n",
    "    key3=[]\n",
    "    key4=[]\n",
    "    key5=[]\n",
    "    key6=[]\n",
    "    key7=[]\n",
    "    cost=np.zeros(n,dtype=int)\n",
    "    data2=np.zeros((m,n),dtype=int)\n",
    "    for i in range(n):\n",
    "        if data1[0][i]==1:            \n",
    "\n",
    "            h1.append(e[i][1])\n",
    "            key1.append(i)\n",
    "#             if data1[2][i]==1:\n",
    "#                 a1=a1+1\n",
    "#             elif data1[3][i]==1:\n",
    "#                 b1=b1+1\n",
    "#             elif data1[4][i]==1:\n",
    "#                 c1=c1+1 \n",
    "#             elif data1[5][i]==1:\n",
    "#                 d1=d1+1\n",
    "#             elif data1[6][i]==1:\n",
    "#                 e1=e1+1\n",
    "\n",
    "        elif data1[1][i]==1:\n",
    "            h2.append(e[i][1])\n",
    "            key2.append(i)\n",
    "#             if data1[2][i]==1:\n",
    "#                 a2=a2+1\n",
    "#             elif data1[3][i]==1:\n",
    "#                 b2=b2+1\n",
    "#             elif data1[4][i]==1:\n",
    "#                 c2=c2+1 \n",
    "#             elif data1[5][i]==1:\n",
    "#                 d2=d2+1\n",
    "#             elif data1[6][i]==1:\n",
    "#                 e2=e2+1\n",
    "            \n",
    "#         if data1[2][i]==1:\n",
    "#             h3.append(e[i][1])\n",
    "#             key3.append(i)\n",
    "            \n",
    "#         elif data1[3][i]==1:\n",
    "#             h4.append(e[i][1])\n",
    "#             key4.append(i)\n",
    "#         elif data1[4][i]==1:\n",
    "#             h5.append(e[i][1])\n",
    "#             key5.append(i)\n",
    "#         elif data1[5][i]==1:\n",
    "#             h6.append(e[i][1])\n",
    "#             key6.append(i)\n",
    "#         elif data1[6][i]==1:\n",
    "#             h7.append(e[i][1])\n",
    "#             key7.append(i)\n",
    "#print(hc)\n",
    "#     print(key1)\n",
    "    \n",
    "    for i in range(1,len(h1)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h1[j-1]<h1[j]:\n",
    "                index=j\n",
    "                var=h1[j]\n",
    "                h1[j]=h1[j-1]\n",
    "                h1[j-1]=var\n",
    "\n",
    "                var2=key1[j]\n",
    "                key1[j]=key1[j-1]\n",
    "                key1[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "\n",
    "    for i in range(1,len(h2)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h2[j-1]<h2[j]:\n",
    "                index=j\n",
    "                var=h2[j]\n",
    "                h2[j]=h2[j-1]\n",
    "                h2[j-1]=var\n",
    "\n",
    "                var2=key2[j]\n",
    "                key2[j]=key2[j-1]\n",
    "                key2[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "#     for i in range(1,len(h3)):\n",
    "#         for j in range(i,0,-1):\n",
    "#             var=0\n",
    "#             var2=0\n",
    "#             if h3[j-1]<h3[j]:\n",
    "#                 index=j\n",
    "#                 var=h3[j]\n",
    "#                 h3[j]=h3[j-1]\n",
    "#                 h3[j-1]=var\n",
    "\n",
    "#                 var2=key3[j]\n",
    "#                 key3[j]=key3[j-1]\n",
    "#                 key3[j-1]=var2\n",
    "#             else:\n",
    "#                 break\n",
    "#     for i in range(1,len(h4)):\n",
    "#         for j in range(i,0,-1):\n",
    "#             var=0\n",
    "#             var2=0\n",
    "#             if h4[j-1]<h4[j]:\n",
    "#                 index=j\n",
    "#                 var=h4[j]\n",
    "#                 h4[j]=h4[j-1]\n",
    "#                 h4[j-1]=var\n",
    "\n",
    "#                 var2=key4[j]\n",
    "#                 key4[j]=key4[j-1]\n",
    "#                 key4[j-1]=var2\n",
    "#             else:\n",
    "#                 break\n",
    "#     for i in range(1,len(h5)):\n",
    "#         for j in range(i,0,-1):\n",
    "#             var=0\n",
    "#             var2=0\n",
    "#             if h5[j-1]<h5[j]:\n",
    "#                 index=j\n",
    "#                 var=h5[j]\n",
    "#                 h5[j]=h5[j-1]\n",
    "#                 h5[j-1]=var\n",
    "\n",
    "#                 var2=key5[j]\n",
    "#                 key5[j]=key5[j-1]\n",
    "#                 key5[j-1]=var2\n",
    "#             else:\n",
    "#                 break\n",
    "                \n",
    "                \n",
    "                \n",
    "#     for i in range(1,len(h6)):\n",
    "#         for j in range(i,0,-1):\n",
    "#             var=0\n",
    "#             var2=0\n",
    "#             if h6[j-1]<h6[j]:\n",
    "#                 index=j\n",
    "#                 var=h6[j]\n",
    "#                 h6[j]=h6[j-1]\n",
    "#                 h6[j-1]=var\n",
    "\n",
    "#                 var2=key6[j]\n",
    "#                 key6[j]=key6[j-1]\n",
    "#                 key6[j-1]=var2\n",
    "#             else:\n",
    "#                 break        \n",
    "                \n",
    "\n",
    "#     for i in range(1,len(h7)):\n",
    "#         for j in range(i,0,-1):\n",
    "#             var=0\n",
    "#             var2=0\n",
    "#             if h7[j-1]<h7[j]:\n",
    "#                 index=j\n",
    "#                 var=h7[j]\n",
    "#                 h7[j]=h7[j-1]\n",
    "#                 h7[j-1]=var\n",
    "\n",
    "#                 var2=key7[j]\n",
    "#                 key7[j]=key7[j-1]\n",
    "#                 key7[j-1]=var2\n",
    "#             else:\n",
    "#                 break \n",
    "    '''            \n",
    "    \n",
    "    for j in range(len(key1)):    \n",
    "        if h1[j]==h1[j-1] and j>=1:\n",
    "            data2[0][key1[j]]=data2[0][key1[j-1]]\n",
    "        else:    \n",
    "            data2[0][key1[j]]=j+1\n",
    "    for j in range(len(key2)):\n",
    "        if h2[j]==h2[j-1] and j>=1:\n",
    "            data2[1][key2[j]]=data2[0][key2[j-1]]\n",
    "        else:    \n",
    "            data2[1][key2[j]]=j+1\n",
    "    for j in range(len(key3)):\n",
    "        if h3[j]==h3[j-1] and j>=1:\n",
    "            data2[2][key3[j]]=data2[2][key3[j-1]]\n",
    "        else:    \n",
    "            data2[2][key3[j]]=j+1\n",
    "    for j in range(len(key4)):\n",
    "        if h4[j]==h4[j-1] and j>=1:\n",
    "            data2[3][key4[j]]=data2[3][key4[j-1]]\n",
    "        else:    \n",
    "            data2[3][key4[j]]=j+1\n",
    "    for j in range(len(key5)):\n",
    "        if h5[j]==h5[j-1] and j>=1:\n",
    "            data2[4][key5[j]]=data2[4][key5[j-1]]\n",
    "        else:    \n",
    "            data2[4][key5[j]]=j+1\n",
    "    for j in range(len(key6)):\n",
    "        if h6[j]==h6[j-1] and j>=1:\n",
    "            data2[5][key6[j]]=data2[5][key6[j-1]]\n",
    "        else:    \n",
    "            data2[5][key6[j]]=j+1\n",
    "    for j in range(len(key7)):\n",
    "        if h7[j]==h7[j-1] and j>=1:\n",
    "            data2[6][key7[j]]=data2[6][key7[j-1]]\n",
    "        else:    \n",
    "            data2[6][key7[j]]=j+1 \n",
    "    \n",
    "  ###############################1#################################  \n",
    "    #2nd approach\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha[1]\n",
    "    for j in range(len(key3)):\n",
    "        if data1[2][key3[j]]==1 and data1[0][key3[j]]==1: \n",
    "            data2[2][key3[j]]=(j+1)*(len(key1)/len(key3))*alpha[2]\n",
    "        else:\n",
    "            data2[2][key3[j]]=(j+1)*(len(key2)/len(key3))*alpha[2]                  \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        if data1[3][key4[j]]==1 and data1[0][key4[j]]==1:                   \n",
    "            data2[3][key4[j]]=(j+1)*(len(key1)/len(key4))*alpha[3]\n",
    "        else :                     \n",
    "            data2[3][key4[j]]=(j+1)*(len(key2)/len(key4))*alpha[3]\n",
    "                             \n",
    "    for j in range(len(key5)):\n",
    "        if data1[4][key5[j]]==1 and data1[0][key5[j]]==1:                  \n",
    "            data2[4][key5[j]]=(j+1)*(len(key1)/len(key5))*alpha[4]\n",
    "        else:      \n",
    "            data2[4][key5[j]]=(j+1)*(len(key2)/len(key5))*alpha[4]\n",
    "    for j in range(len(key6)):\n",
    "        if data1[5][key6[j]]==1 and data1[0][key6[j]]==1:                    \n",
    "            data2[5][key6[j]]=(j+1)*(len(key1)/len(key6))*alpha[5]\n",
    "        else:                    \n",
    "             data2[5][key6[j]]=(j+1)*(len(key2)/len(key6))*alpha[5]               \n",
    "    for j in range(len(key7)):\n",
    "        if data1[6][key7[j]]==1 and data1[0][key7[j]]==1:\n",
    "            data2[6][key7[j]]=(j+1)*(len(key1)/len(key7))*alpha[6]\n",
    "        else:\n",
    "             data2[6][key7[j]]=(j+1)*(len(key2)/len(key7))*alpha[6]\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    #1st approach\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha[1]\n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)*alpha[2]              \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        data2[3][key4[j]]=(j+1)*alpha[3]\n",
    "        \n",
    "                             \n",
    "    for j in range(len(key5)):               \n",
    "        data2[4][key5[j]]=(j+1)*alpha[4]\n",
    "       \n",
    "    for j in range(len(key6)):\n",
    "        data2[5][key6[j]]=(j+1)*alpha[5]\n",
    "                    \n",
    "    for j in range(len(key7)):\n",
    "        data2[6][key7[j]]=(j+1)*alpha[6]\n",
    "    '''   \n",
    "    '''\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*((beta[0]*len(key1))/(beta[1]*len(key2)))*alpha[1]\n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)*((beta[2]*len(key3))/(beta[2]*len(key3)))*alpha[2]\n",
    "                         \n",
    "        \n",
    "    for j in range(len(key4)):           \n",
    "        #data2[3][key4[j]]=(j+1)*((beta[2]*len(key3))/(beta[3]*len(key4)))*alpha[3]\n",
    "        if data1[3][key4[j]]==1 and data1[0][key4[j]]==1:                   \n",
    "            data2[3][key4[j]]=(j+1)*((beta[2]*len(key3))/(beta[3]*len(key4)))*alpha[3]\n",
    "        else :                     \n",
    "            data2[3][key4[j]]=(j+1)*((beta[2]*len(key3))/(beta[3]*len(key4)))*alpha[3]\n",
    "                             \n",
    "    for j in range(len(key5)):\n",
    "        data2[4][key5[j]]=(j+1)*((beta[2]*len(key3))/(beta[4]*len(key5)))*alpha[4]      \n",
    "    for j in range(len(key6)):                 \n",
    "        data2[5][key6[j]]=(j+1)*((beta[2]*len(key3))/(beta[5]*len(key6)))*alpha[5]  \n",
    "    for j in range(len(key7)):                 \n",
    "        data2[6][key7[j]]=(j+1)*((beta[2]*len(key3))/(beta[6]*len(key7)))*alpha[6] \n",
    "    '''\n",
    "    #######################################################################    \n",
    "    \n",
    "    ####################################################################### \n",
    "   \n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*((beta[1]*len(key2))/(beta[0]*len(key1)))*alpha[1]\n",
    "    \n",
    "#     for j in range(len(key3)):\n",
    "#         data2[2][key3[j]]=(j+1)*alpha[2]\n",
    "                         \n",
    "        \n",
    "#     for j in range(len(key4)):           \n",
    "#         #data2[3][key4[j]]=(j+1)*((beta[2]*len(key3))/(beta[3]*len(key4)))*alpha[3]\n",
    "#         if data1[3][key4[j]]==1 and data1[0][key4[j]]==1:                   \n",
    "#             data2[3][key4[j]]=(j+1)*((beta[3]*len(key4))/(beta[2]*len(key3)))*alpha[3]\n",
    "#         else :                     \n",
    "#             data2[3][key4[j]]=(j+1)*((beta[3]*len(key4))/(beta[2]*len(key3)))*alpha[3]\n",
    "                             \n",
    "#     for j in range(len(key5)):\n",
    "#         data2[4][key5[j]]=(j+1)*((beta[4]*len(key5))/(beta[2]*len(key3)))*alpha[4]\n",
    "       \n",
    "           \n",
    "#     for j in range(len(key6)):                 \n",
    "#         data2[5][key6[j]]=(j+1)*((beta[5]*len(key6))/(beta[2]*len(key3)))*alpha[5]\n",
    "    \n",
    "#     for j in range(len(key7)):                 \n",
    "#         data2[6][key7[j]]=(j+1)*((beta[6]*len(key7))/(beta[2]*len(key3)))*alpha[6]    \n",
    "        \n",
    "        \n",
    "    for j in range(n):\n",
    "        summ=0\n",
    "        for i in range(m):\n",
    "       \n",
    "            summ=summ+data2[i][j] \n",
    "        cost[j]=summ\n",
    "        \n",
    "        \n",
    "    ################\n",
    "    \n",
    "    \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "   \n",
    "    \n",
    "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "#     report_index(index,data1,e):  \n",
    "    max_size=0\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1 \n",
    "        if count>max_size:\n",
    "            max_size=count\n",
    "        sizes[i]=count\n",
    "    print(sizes)    \n",
    "    #############################33\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################\n",
    "        \n",
    "        \n",
    "        \n",
    "  \n",
    "    select_sizes=np.zeros(m,dtype=int)\n",
    "   \n",
    "    size_final=np.zeros(m,dtype=int)\n",
    "\n",
    "    \n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "   \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
    "\n",
    "  \n",
    "\n",
    "    #########objective function#####################\n",
    "    \n",
    "#     Lp_prob += 2*X[n+1]+10*X[n+2]+9*X[n+3]+3*X[n+4]\n",
    "    \n",
    "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)]) \n",
    "    #Lp_prob+=1  \n",
    "    \n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= math.floor(beta[i]*sizes[i])\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= math.ceil((beta[i]+eps)*sizes[i])\n",
    "           # Lp_prob += p.lpSum([(X[j])*(data1[i][j])*(sizes[i]-report_index(j,i,data1,e)+1) for j in range(n)]) <= X[n+i+1]\n",
    "                    \n",
    "\n",
    "        \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"objective is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    print(\"discripency is:\") \n",
    "    print(p.value(X[n]))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "#             if(data1[2][i]==1):\n",
    "#                 print(\"no\")\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_svm(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "#     sens=['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']\n",
    "#     import random\n",
    "#     for i in range(X_train.shape[0]):\n",
    "#             p=random.randint(0,1)\n",
    "#             #q=random.randint(2,6)\n",
    "#             for j in range(len(sens)):\n",
    "#                 if j ==p:\n",
    "#                     X_train.loc[i,sens[p]]=1\n",
    "# #                 if j ==q:\n",
    "# #                     X_train.loc[i,sens[p]]=1    \n",
    "# #                 if j!=p and j!=q:\n",
    "# #                     X_train.loc[i,sens[j]]=0\n",
    "#                 if j!=p and j!=q:\n",
    "#                     X_train.loc[i,sens[j]]=0\n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=svm.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without accuracy ---> 2\n",
    "def main(datax, y_test, y_test_pred,e): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"SVM accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    \n",
    "    \n",
    "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
    "    #gamma=.05,.06,.07\n",
    "    #delta1=[.80,.85,.90,.95]\n",
    "# (for reproducibility)  \n",
    "\n",
    "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
    "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
    " \n",
    "#     delta1=np.arange(1,.79,-.01)\n",
    "    \n",
    "#     gama=[.05,.1,.15,.2,.25]\n",
    "#     epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
    "\n",
    "#ADULT ZAFAR =? epsilon=[0.088 ,0.1656, 0.168,  0.211, 0.251 ] \n",
    " \n",
    "#agarwal=> epsilon=[ 0.071, 0.1271, 0.2437, 0.27 ]\n",
    "    '''\n",
    "    gamma2=[[0.0964, 0.1998, 0.1657, 0.24, 0.2326, 0.1467, 0.1391] ,\n",
    "    [0.1026, 0.1659, 0.14257, 0.1533, 0.2054, 0.1573, 0.1130],\n",
    "    [0.1255, 0.1104, 0.1123, 0.0666, 0.1460, 0.1409, 0.0956],\n",
    "    [0.1124, 0.0637, 0.0789, 0.0466, 0.0841, 0.0868, 0.0695]]\n",
    "    gamma=np.zeros((4,7),dtype=float)\n",
    "    to=[1,0,2,5,4,3,6]\n",
    "    k=0\n",
    "    for i in range(7):\n",
    "        for j in range(4):\n",
    "            gamma[j][i]=gamma2[j][to[k]]\n",
    "        k=k+1\n",
    "    print(gamma)    \n",
    "    alpha=[[1,1,1,1,1,1,1]]\n",
    "    '''\n",
    "    #gama=[0.0869, 0.0521,0.0782, 0.0608,0.0434, 0.1,0.069,0.0434,0.034]\n",
    "    epsilon=[.01]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "#     for delta in delta1:\n",
    "    #4 gamma=[0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348   ]\n",
    "\n",
    "    #1 gamma=[0.259147,   0.0730028, 0.210139, 0.0893443, 0.306931, 0.0933333,  0.0347826]\n",
    "    #gamma=[0.196178,0.126722,   0.179654, 0.140164,     0.153465,   0.133333,  0.0695652]\n",
    "    '''\n",
    "    #agarwal\n",
    "    gamma2=  [[0.175442, 0.196178, 0.255673, 0.259147],\n",
    "      [0.142103 ,0.126722 ,0.0766758 ,0.0730028],\n",
    "      [ 0.166039 , 0.179654,  0.208084,  0.210139],\n",
    "      [0.164754 , 0.140164 , 0.101639 , 0.0893443],\n",
    "      [0.153465 , 0.153465,  0.287129 , 0.306931],\n",
    "      [0.14, 0.133333  ,0.0933333 , 0.0933333],\n",
    "      [0.104348, 0.0695652,0.0434783,0.0347826]]\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #agar\n",
    "    # gamma2=[[0.175442], [0.142103],[0.166039],[0.164754],[0.153465],[0.14],[0.104348]]\n",
    "    \n",
    "    #gamma2=[[0.175442], [0.142103],[0.166039],[0.164754],[0.153465],[0.14],[0.104348]]\n",
    "    \n",
    "    \n",
    "    #bilal\n",
    "   # gamma2=[[.109868],[.15679],[.124507],[.111475],[.185643],[.140],[.0782608]]\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "     #bilal\n",
    "    gamma2=[[ 7.73645546,  8.12672176,  8.99908173, 10.30762167, 11.98347107, 13.08539945,\n",
    "     13.86593205, 14.09550046, 14.02662994, 15.22038567, 15.6795225 ]\n",
    "    ,[26.09922918, 25.51297362 ,24.15590055, 22.42970362 ,20.56237108 ,19.45499946\n",
    "     ,17.92422104 ,16.13288459, 14.07013354, 12.202801,   10.98686353]\n",
    "    ,[ 9.33333333,  9.33333333  ,8.66666667,  8.0      ,   9.33333333 , 9.33333333\n",
    "      ,9.33333333 , 9.33333333 ,13.33333333 ,11.33333333 ,14.0        ]\n",
    "    ,[29.7029703  ,29.45544554 ,27.97029703 ,27.47524752 ,27.22772277 ,25.24752475\n",
    "     ,24.25742574 ,24.25742574 ,21.78217822 ,19.30693069, 18.56435644]\n",
    "    ,[ 9.42622951 , 9.50819672 ,10.08196721 ,10.24590164  ,9.91803279, 10.08196721\n",
    "     ,10.40983607 ,10.98360656 ,11.39344262, 11.39344262 ,11.14754098]\n",
    "    ,[6.08695652 ,4.34782609 ,4.34782609 ,5.2173913,  6.08695652 ,7.82608696\n",
    "     ,8.69565217 ,6.08695652 ,5.2173913  ,6.95652174 ,7.82608696]\n",
    "    ,[21.27932865 ,20.9796198  ,20.23462922 ,19.36119198 ,18.5305703,  18.1024148\n",
    "     ,17.1775989 , 15.81606439, 14.16338414, 13.23000514 ,12.45076212]]\n",
    "    \n",
    "    gamma2=[[.07736455,.1198347107,.138659,.140266,.15679],\n",
    "[.26099,.2056237108,.179242,.140701,.109868],\n",
    "[.09333,.0933333,.093333,.13333,.140], \n",
    "[.297029,.27227,.2425742,.217821,.185643],\n",
    "[.097029,.099180,.104098,.11393,.111475],\n",
    "[.0608695652,.0608695,.086956,.052173,.0782608],\n",
    "[.21212793,0.185220071930125,.17177,.14163,.124507]\n",
    "]\n",
    "    gamma=np.transpose(gamma2)\n",
    "    '''\n",
    "\n",
    "#     gamma=[[0.30355010313755293, 0.10743801652892562, 0.252269224182223, 0.13278688524590163, 0.3118811881188119, 0.1, 0.13043478260869565]\n",
    "# ]\n",
    "    '''\n",
    "    alpha=[[1,1,1,1,1,1,1],[.1,1,1,1,1,1,1], [.01,1,1,1,1,1,1],[.001,1,1,1,1,1,1],\n",
    "           [1,.1,1,1,1,1,1], [1,.01,1,1,1,1,1],[1,.001,1,1,1,1,1],\n",
    "           [1,1,.1,1,1,1,1], [1,1,.01,1,1,1,1],[1,1,.001,1,1,1,1],\n",
    "           [1,1,1,.1,1,1,1], [1,1,1,.01,1,1,1],[1,1,1,.001,1,1,1],\n",
    "           [1,1,1,1,.1,1,1], [1,1,1,1,.01,1,1,],[1,1,1,1,.001,1,1],\n",
    "           [1,1,1,1,1,.1,1], [1,1,1,1,1,.01,1],[1,1,1,1,1,.001,1],\n",
    "           [1,1,1,1,1,1,.1], [1,1,1,1,1,1,.01],[1,1,1,1,1,1,.001],\n",
    "        [.1,.1,1,1,1,1,1],[.01,.01,1,1,1,1,1], [.001,.001,1,1,1,1,1],[.001,.01,1,1,1,1,1],[.001,.1,1,1,1,1,1],\n",
    "         [.01,.1,1,1,1,1,1] ]\n",
    "    '''  \n",
    "     #alpha=[[1,1,1,1,1,1,1], [1,1,1,1,.1,1,1], [1,1,1,1,.01,1,1,],[1,1,1,1,.001,1,1] ]         \n",
    "    '''\n",
    "    alpha=[[1,1,1,1,1,1,1], [1,1,1,1,.01,1,1], [.1,1,1,1,.01,1,1,],[1,.1,1,1,.01,1,1],[1,1,.01,1,.01,1,1], [1,1,.1,1,.1,1,1], [.1,1,.01,1,.01,1,1], [.01,1,.1,1,.1,1,1] ]        \n",
    "    '''       \n",
    "           #alpha=[90,40,100,10,4,1,10]\n",
    "    #alpha=[ 9211,  4356, 11678,  1220,   404,   150 ,  115]\n",
    "    a=0\n",
    "    '''\n",
    "    #LP-5\n",
    "    gamma=[[0.2591466724568451, 0.07392102846648302, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.06956521739130435],\n",
    "[0.24025621539463685, 0.09182736455463728, 0.20106182565507794, 0.10491803278688525, 0.27970297029702973, 0.11333333333333333, 0.06086956521739131],\n",
    "[0.2213657583324286, 0.10996326905417815, 0.191984928926186, 0.11967213114754098, 0.25, 0.12666666666666668, 0.08695652173913043],\n",
    "[0.2024753012702204, 0.1283287419651056, 0.18282240109607809, 0.13524590163934427, 0.22277227722772278, 0.14, 0.11304347826086956],\n",
    "[0.18358484420801216, 0.14646464646464646, 0.17374550436718617, 0.15, 0.19306930693069307, 0.15333333333333332, 0.1391304347826087],\n",
    "[0.16469438714580392, 0.16483011937557393, 0.16466860763829422, 0.16475409836065574, 0.16584158415841585, 0.16666666666666666, 0.16521739130434782]]\n",
    "    alpha=[[1,1,1,1,1,1,1]]\n",
    "    '''\n",
    "\n",
    "    #agarwal\n",
    "    '''\n",
    "    gamma2=    [[0.175442, 0.196178, 0.255673, 0.259147],\n",
    "                [0.142103,0.126722,0.0766758,0.0730028],\n",
    "                [0.166039,0.179654,0.208084,0.210139],\n",
    "                [0.164754,0.140164,0.101639,0.0893443],\n",
    "                [0.153465,0.153465,0.287129,0.306931],\n",
    "                [0.14,0.133333,0.0933333,0.0933333],\n",
    "                [0.104348,0.0695652,0.0434783,0.0347826]]\n",
    "                \n",
    "    gamma=np.transpose(gamma2)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #\n",
    "    gamma=[[0.143,  0.0594, 0.1227, 0.0663, 0.1336, 0.04 ,  0.026 ],\n",
    " [0.1061 ,0.0463 ,0.0911 ,0.0524, 0.1113 ,0.0266, 0.026 ],\n",
    " [0.0776 ,0.0525 ,0.0703 ,0.0639, 0.0866, 0.0333, 0.0347],\n",
    " [0.0772, 0.0757 ,0.0753, 0.0827, 0.094,  0.0933, 0.0782]] \n",
    "    alpha=[[1,1,1,1,1,1,1]]\n",
    "    '''\n",
    "    \n",
    "     #adult LP4 figure varying beta\n",
    "    '''\n",
    "    gamma=[[0.02,.02,.02,.02,.02,.02,.02 ],\n",
    "           [0.025,.025,.025,.025,.025,.025,.025 ],\n",
    "           [0.05,.05,.05,.05,.05,.05,.05 ],          \n",
    "        [0.10,.10,.10,.10,.10,.10,.10 ],\n",
    " [.12 ,.12 ,.12 ,.12,.12 ,.12 ,.12 ],\n",
    " [.14 ,.14 ,.14 ,.14,.14 ,.14 ,.14 ],\n",
    " [.16 ,.16 ,.16 ,.16,.16 ,.16 ,.16 ],\n",
    " [.18 ,.18 ,.18 ,.18,.18 ,.18 ,.18 ],\n",
    " [.20 ,.20 ,.20 ,.20,.20 ,.20 ,.20 ],\n",
    "           [0.25,.25,.25,.25,.25,.25,.25 ],\n",
    "           [0.3,.3,.3,.3,.3,.3,.3 ],\n",
    "           [0.35,.35,.35,.35,.35,.35,.35 ]]\n",
    "    '''\n",
    "    #bilal\n",
    "    gamma2=[[.20,.16,.1407,.1098],\n",
    "        [.20,.16,.1402,.1567]]\n",
    "       \n",
    "    gamma=np.transpose(gamma2)\n",
    "    alpha=[[1,1]]\n",
    "    epsilon=[.01]\n",
    "    t=0\n",
    "    #for t in range(gamma.shape[0]):\n",
    "    #for t in range(28):\n",
    "    for new in range(4):\n",
    "        k=0\n",
    "        for t in range(1):\n",
    "            for eps in epsilon:\n",
    "                u1,u2=min_sum_lpca(data,gamma[new],eps,e,alpha[t])\n",
    "                #######################Disp_impact#######################  \n",
    "                print(\"gamma-epsilon-delta\",gamma[new],eps)\n",
    "                accu_all=[]\n",
    "                DP_all=[]\n",
    "                precision_all=[]\n",
    "                recall_all=[]\n",
    "                ar_all=[]\n",
    "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "                count=0\n",
    "                print(\"<--------------------------------------->\")\n",
    "                print(\"iteration t\",k)\n",
    "                k=k+1\n",
    "        #                 for alpha in np.arange(0,1.05,0.05):\n",
    "        #                     print(\"alpha: \",alpha)\n",
    "        #                     for i in range(n):\n",
    "\n",
    "        #                         z=random()\n",
    "        #                         if z < alpha:\n",
    "        #                                fi[i]= u1[i] \n",
    "\n",
    "        #                         else:\n",
    "        #                                fi[i]= r2[i]\n",
    "\n",
    "                for i in range(n):\n",
    "                     fi[i] = u1[i]\n",
    "\n",
    "\n",
    "                for j in range(s):\n",
    "                    print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "                    TP=0\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TN=0\n",
    "                    precision=0\n",
    "                    recall=0\n",
    "                    for i in range(n):\n",
    "                         if data[j][i]== 1 :                        \n",
    "                            if fi[i]==1 and r[i]==1:\n",
    "                                TP=TP+1\n",
    "                            if fi[i]==1 and r[i]==-1:\n",
    "                                FP=FP+1 \n",
    "                            if fi[i]==-1 and r[i]==1:\n",
    "                                FN=FN+1\n",
    "                            if fi[i]==-1 and r[i]==-1:\n",
    "                                TN=TN+1    \n",
    "                    if TP+FP !=0:\n",
    "                        precision=float(TP/(TP+FP))\n",
    "                    #print(\"precision\",precision)\n",
    "                    if TP+FN !=0:    \n",
    "                        recall=float(TP/(TP+FN))\n",
    "                    #print(\"recall\",recall)\n",
    "\n",
    "                    precision_all.append(precision)\n",
    "                    recall_all.append(recall)\n",
    "                    #print(\"TP,FP,TN,FN\")\n",
    "                    #print(TP,FP,TN,FN)\n",
    "\n",
    "                    a=0\n",
    "                    b=0\n",
    "                    acc1=0\n",
    "                    acc2=0\n",
    "                    for i in range(n):\n",
    "                            if data[j][i]== 1 :\n",
    "                                a=a+1\n",
    "                                if fi[i]==1:\n",
    "                                     acc1=acc1+1 \n",
    "\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                    a1=float(acc1/a)\n",
    "\n",
    "\n",
    "\n",
    "        #                         print(a)\n",
    "        #                         print(acc1)\n",
    "        #                         print(a1)\n",
    "                    ar_all.append(a1)\n",
    "\n",
    "                count = count+1\n",
    "                maxi=max(ar_all)\n",
    "                mini= min(ar_all)\n",
    "                DP=float(maxi-mini)\n",
    "                print(\"individual acceptance rates\")\n",
    "                print(ar_all)\n",
    "                print(\"individul precision\")\n",
    "                print(precision_all)\n",
    "                print(\"individual recall\")\n",
    "                print(recall_all)\n",
    "                print(\"DP all\")\n",
    "                print(DP)\n",
    "                f_acc=0\n",
    "                for i in range(n):\n",
    "                     if fi[i] == r[i]:\n",
    "                            f_acc=f_acc+1\n",
    "                f_acc_l=float((f_acc*100)/n) \n",
    "\n",
    "        #######################################################################33   \n",
    "\n",
    "        #                         print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                TP=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TN=0\n",
    "                precision=0\n",
    "                recall=0\n",
    "                accu=0\n",
    "                for i in range(n):\n",
    "                        if fi[i]==1 and r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        if fi[i]==1 and r[i]==-1:\n",
    "                            FP=FP+1 \n",
    "                        if fi[i]==-1 and r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        if fi[i]==-1 and r[i]==-1:\n",
    "                            TN=TN+1    \n",
    "\n",
    "                if TP+FP!=0:\n",
    "                    precision=float(TP/(TP+FP))\n",
    "                print(\"precision all\",precision)\n",
    "                if TP+FN!=0:\n",
    "                    recall=float(TP/(TP+FN))\n",
    "\n",
    "\n",
    "                print(\"recall all\",recall)\n",
    "                accu=float((TP+TN)/(TP+FN+TN+FP))\n",
    "\n",
    "\n",
    "                print(\"accuracy all\",accu)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"TP,FP,TN,FN\")\n",
    "                print(TP,FP,TN,FN)\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "\n",
    "\n",
    "    print(\"<--------------------------------------->\")\n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without accuracy\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "\n",
    "# Add column names to data set\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Read in train data\n",
    "adult_train = pd.read_csv('data/adult_actual/adult_train_data.csv', header=None, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_train = adult_train.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Read in test data\n",
    "adult_test = pd.read_csv('data/adult_actual/adult_test_data.csv', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_test = adult_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Remove '.' in income column\n",
    "adult_test['income'] = adult_test['income'].apply(lambda x: '>50k' if x=='>50k.'  else '<=50k')\n",
    "\n",
    "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in object_col:\n",
    "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
    "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
    "\n",
    "# Perform an mssing assessment in each column of the dataset.\n",
    "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
    "col_missing_pct.sort_values(ascending=False)\n",
    "\n",
    "# Remove data entries with missing value\n",
    "adult_train = adult_train.dropna(axis=0, how='any')\n",
    "adult_test = adult_test.dropna(axis=0, how='any')\n",
    "\n",
    "\n",
    "for col in object_col:\n",
    "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')\n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())    \n",
    "\n",
    "adult_train.reset_index(drop=True, inplace=True)\n",
    "adult_test.reset_index(drop=True, inplace=True)\n",
    "p=adult_train.shape[0]\n",
    "q =adult_test.shape[0]\n",
    "# reducing dimensionality of some very sparse features\n",
    "for i in range(0,p):\n",
    "    if adult_train.loc[i,'native-country'] not in [\"united-states\"] :\n",
    "               adult_train.loc[i,\"native-country\"] = \"non-united-stated\"        \n",
    "    if adult_train.loc[i,\"education\"] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"prim-middle-school\"\n",
    "    elif adult_train.loc[i,\"education\"] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"high-school\"   \n",
    "    if adult_train.loc[i,'income'] in [\">50k\"] :\n",
    "               adult_train.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_train.loc[i,\"income\"] = 0         \n",
    "#reducing dimensionality of some very sparse features\n",
    "for i in range(0,q):                \n",
    "    if adult_test.loc[i,'native-country'] not in [\"united-states\"]:\n",
    "               adult_test.loc[i,'native-country'] = \"non-united-stated\"\n",
    "    if adult_test.loc[i,'education'] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_test.loc[i,'education'] = \"prim-middle-school\"\n",
    "    elif adult_test.loc[i,'education'] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_test.loc[i,'education'] = \"high-school\"   \n",
    "    if adult_test.loc[i,'income'] in [\">50k\",\">50k.\"] :\n",
    "               adult_test.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_test.loc[i,\"income\"] = 0            \n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())\n",
    "DATA=pd.concat([adult_train,adult_test],ignore_index=True)\n",
    "# print(DATA.tail())\n",
    "m=DATA.shape[1]\n",
    "\n",
    "dat=DATA.iloc[:,0:m-1]\n",
    "\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "num_col = dat.dtypes[dat.dtypes != 'object'].index\n",
    "features_log_minmax_transform = pd.DataFrame(data = dat)\n",
    "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
    "\n",
    "display(features_log_minmax_transform.head())\n",
    "\n",
    "# sens=DATA[['sex','race']]\n",
    "\n",
    "Data_c = pd.get_dummies(features_log_minmax_transform, columns=['sex','race','workclass','education','marital-status','occupation','relationship','native-country'], prefix =['s','r','work','edu','ms','occ','rls','nc'])\n",
    "\n",
    "\n",
    "        \n",
    "r=DATA.iloc[:,m-1]\n",
    "\n",
    "print(Data_c)\n",
    "print(DATA['income'].value_counts())\n",
    "\n",
    "\n",
    "# X_test,Y_test_pred,Y_test,e = adult_svm(Data_c , r)\n",
    "\n",
    "# X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# sens=X_test[['s_male', 's_female']]\n",
    "\n",
    "# sensitive = sens.T\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Beta Plot for LP4 to show beta variation from .1 to .2\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_svm(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    sens=['s_male', 's_female' ]\n",
    "    print(sens[0],sens[1],X_train[:,'s_male'].shape[0],X_train['s_male',:].shape[1])\n",
    "    import random\n",
    "    for i in range(X_train.shape[0]):\n",
    "        print(X_train.loc[i,'s_male'])\n",
    "        \n",
    "    for i in range(X_train.shape[0]):\n",
    "            p=random.randint(0,1)\n",
    "            #q=random.randint(2,6)\n",
    "            print(X_train.loc[i,'s_male'])\n",
    "            print(X_train.loc[i,'s_female'])\n",
    "            if p ==0:\n",
    "                X_train.loc[i,'s_male']=1\n",
    "                X_train.loc[i,'s_female']=0\n",
    "#                 if j ==q:\n",
    "#                     X_train.loc[i,sens[p]]=1    \n",
    "#                 if j!=p and j!=q:\n",
    "#                     X_train.loc[i,sens[j]]=0\n",
    "            else:\n",
    "                X_train.loc[i,'s_male']=0\n",
    "                X_train.loc[i,'s_female']=1\n",
    "    #X_train.loc[i,'s_male']\n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=svm.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without accuracy\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "\n",
    "# Add column names to data set\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Read in train data\n",
    "adult_train = pd.read_csv('data/adult_actual/adult_train_data.csv', header=None, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_train = adult_train.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Read in test data\n",
    "adult_test = pd.read_csv('data/adult_actual/adult_test_data.csv', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_test = adult_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Remove '.' in income column\n",
    "adult_test['income'] = adult_test['income'].apply(lambda x: '>50k' if x=='>50k.'  else '<=50k')\n",
    "\n",
    "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in object_col:\n",
    "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
    "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
    "\n",
    "# Perform an mssing assessment in each column of the dataset.\n",
    "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
    "col_missing_pct.sort_values(ascending=False)\n",
    "\n",
    "# Remove data entries with missing value\n",
    "adult_train = adult_train.dropna(axis=0, how='any')\n",
    "adult_test = adult_test.dropna(axis=0, how='any')\n",
    "\n",
    "\n",
    "for col in object_col:\n",
    "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')\n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())    \n",
    "\n",
    "adult_train.reset_index(drop=True, inplace=True)\n",
    "adult_test.reset_index(drop=True, inplace=True)\n",
    "p=adult_train.shape[0]\n",
    "q =adult_test.shape[0]\n",
    "# reducing dimensionality of some very sparse features\n",
    "for i in range(0,p):\n",
    "    if adult_train.loc[i,'native-country'] not in [\"united-states\"] :\n",
    "               adult_train.loc[i,\"native-country\"] = \"non-united-stated\"        \n",
    "    if adult_train.loc[i,\"education\"] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"prim-middle-school\"\n",
    "    elif adult_train.loc[i,\"education\"] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"high-school\"   \n",
    "    if adult_train.loc[i,'income'] in [\">50k\"] :\n",
    "               adult_train.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_train.loc[i,\"income\"] = 0         \n",
    "#reducing dimensionality of some very sparse features\n",
    "for i in range(0,q):                \n",
    "    if adult_test.loc[i,'native-country'] not in [\"united-states\"]:\n",
    "               adult_test.loc[i,'native-country'] = \"non-united-stated\"\n",
    "    if adult_test.loc[i,'education'] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_test.loc[i,'education'] = \"prim-middle-school\"\n",
    "    elif adult_test.loc[i,'education'] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_test.loc[i,'education'] = \"high-school\"   \n",
    "    if adult_test.loc[i,'income'] in [\">50k\",\">50k.\"] :\n",
    "               adult_test.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_test.loc[i,\"income\"] = 0            \n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())\n",
    "DATA=pd.concat([adult_train,adult_test],ignore_index=True)\n",
    "# print(DATA.tail())\n",
    "m=DATA.shape[1]\n",
    "\n",
    "dat=DATA.iloc[:,0:m-1]\n",
    "\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "num_col = dat.dtypes[dat.dtypes != 'object'].index\n",
    "features_log_minmax_transform = pd.DataFrame(data = dat)\n",
    "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
    "\n",
    "display(features_log_minmax_transform.head())\n",
    "\n",
    "# sens=DATA[['sex','race']]\n",
    "\n",
    "Data_c = pd.get_dummies(features_log_minmax_transform, columns=['sex','race','workclass','education','marital-status','occupation','relationship','native-country'], prefix =['s','r','work','edu','ms','occ','rls','nc'])\n",
    "\n",
    "\n",
    "        \n",
    "r=DATA.iloc[:,m-1]\n",
    "\n",
    "print(Data_c)\n",
    "print(DATA['income'].value_counts())\n",
    "\n",
    "\n",
    "X_test,Y_test_pred,Y_test,e = adult_svm(Data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "sens=X_test[['s_male', 's_female']]\n",
    "\n",
    "sensitive = sens.T\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,Y_test_pred,Y_test,e = adult_svm(Data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "sens=X_test[['s_male', 's_female']]\n",
    "\n",
    "sensitive = sens.T\n",
    "\n",
    " \n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP,FP,TN,FN\n",
    "325 290 3598 143\n",
    "for af_am precision 0.5284552845528455\n",
    "for af_am recall 0.6944444444444444\n",
    "for af_am accept rate 0.14118457300275483\n",
    "828 189 6226 1968\n",
    "for white precision 0.8141592920353983\n",
    "for white recall 0.296137339055794\n",
    "for white accept rate 0.11041146455325154\n",
    "1153 479 9824 2111\n",
    "for all precision 0.7064950980392157\n",
    "for all recall 0.35324754901960786\n",
    "for all acc rate 0.12029188472027715\n",
    "for all accuracy: 0.8090955996167171\n",
    "Demo-Parity: 0.03077310844950329\n",
    "\n",
    "    \n",
    "TP,FP,TN,FN\n",
    "227 159 3729 241\n",
    "for af_am precision 0.5880829015544041\n",
    "for af_am recall 0.48504273504273504\n",
    "for af_am accept rate 0.08861340679522497\n",
    "1698 745 5670 1098\n",
    "for white precision 0.695047073270569\n",
    "for white recall 0.6072961373390557\n",
    "for white accept rate 0.26522635978721093\n",
    "1925 904 9399 1339\n",
    "for all precision 0.68045245669848\n",
    "for all recall 0.5897671568627451\n",
    "for all acc rate 0.2085206751676863\n",
    "for all accuracy: 0.8346723667723152\n",
    "Demo-Parity: -0.17661295299198596\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################   ##bilal\n",
    "train test eval      corrupt train test eval    train train eval    corrupt train train eval   corrupt test test eval\n",
    "dp 0.0464 acc 0.8366   dp 0.1785   acc 0.8500   dp .0417  acc .8314   dp .004   acc 0.8447     dp .0043   acc 0.8368\n",
    "\n",
    "# ######################   #padala\n",
    "Dp 0.0307 acc 0.8090   Dp -0.1766 acc 0.8346    Dp 0.0336  acc 0.8355  dp .001  acc 0.8925     Dp  0.1571 acc 0.8205\n",
    "\n",
    "# ####################        #agarwal\n",
    "dp 0.0149  acc 0.8494   dp 0.1812  acc 0.8657   DP 0.0146  acc 0.8558  dp 0.0054   acc 0.8770  DP 0.004  acc 0.8494\n",
    "    \n",
    "# ####################        #madras\n",
    "dp 0.0185 acc 0.8323    dp 0.1972   acc 0.8505                                                  0.019   .8317      \n",
    "    \n",
    "# ####################        #LPCA\n",
    "(beta .20)0.00002 0.8466            .0002 0.8435                                                           .0005837 0.8648\n",
    "(beta .16)0.0005 0.8446             .0005 0.8438                                                           .00012866  0.8633\n",
    "\n",
    "# ####################      #moritz hardt  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "0.1446 0.8636\n",
    "0.0900 0.8421\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ####################        #madras\n",
    "data--adult--model_class-WeightedDemParWassGan--model_fair_coeff-0_2/checkpoints/Epoch_600_Valid/test_metrics.csv\n",
    "dp 0.0185 acc 0.8323  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corrupt test test eval (new evaluation)test corrupt on non corrupt test\n",
    "\n",
    "\n",
    "# ##########################   ##bilal\n",
    "train test eval      corrupt train test eval    train train eval    corrupt train train eval   corrupt test test eval\n",
    "dp 0.0464 acc 0.8366   dp 0.1785   acc 0.8500   dp .0417  acc .8314   dp .004   acc 0.8447     dp .0043   acc 0.8368\n",
    "\n",
    "# ######################   #padala\n",
    "Dp 0.0307 acc 0.8090   Dp -0.1766 acc 0.8346    Dp 0.0336  acc 0.8355  dp .001  acc 0.8925     Dp -0.1006 acc 0.8153\n",
    "\n",
    "# ####################        #agarwal\n",
    "dp 0.0149  acc 0.8494   dp 0.1812  acc 0.8657   DP 0.0146  acc 0.8558  dp 0.0054   acc 0.8770  DP 0.0149  acc 0.8494\n",
    "    \n",
    "# ####################        #madras\n",
    "dp 0.0185 acc 0.8323    dp 0.1972   acc 0.8505                                                 \n",
    "    \n",
    "# ####################        #LPCA\n",
    "0.00002 0.8466            .0002 0.8435                                                           0.1849 0.8650\n",
    "0.0005 0.8446             .0005 0.8438                                                           0.1446 0.8636\n",
    "                                                                                                 0.0900 0.8421\n",
    "\n",
    "# ####################      #moritz hardt  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prec=[[0.7717908082408875, 0.5623800383877159, 0.7483811285846439, 0.5083333333333333, 0.6055045871559633, 0.25, 0.7142857142857143],\n",
    "[0.7963636363636364, 0.5257048092868989, 0.7586034912718205, 0.3968253968253968, 0.5257731958762887, 0.25, 0.5555555555555556],\n",
    "[0.8455598455598455, 0.5081967213114754, 0.7961282516636419, 0.2898550724637681, 0.4827586206896552, 0.15, 0.5714285714285714],\n",
    "[0.866601752677702, 0.4809384164222874, 0.7921541637990365, 0.2214765100671141, 0.36486486486486486, 0.13043478260869565, 0.4]\n",
    "     ]\n",
    "\n",
    "rec=[[0.5225321888412017, 0.6260683760683761, 0.5492192803801765, 0.3765432098765432, 0.5238095238095238, 0.26666666666666666, 0.3333333333333333],\n",
    "[0.4699570815450644, 0.6773504273504274, 0.5162932790224033, 0.30864197530864196, 0.40476190476190477, 0.26666666666666666, 0.3333333333333333],\n",
    "[0.3916309012875536, 0.6623931623931624, 0.4467073998642227, 0.24691358024691357, 0.3333333333333333, 0.2, 0.26666666666666666],\n",
    "[0.31831187410586553, 0.7008547008547008, 0.3906992532247115, 0.2037037037037037, 0.21428571428571427, 0.2, 0.26666666666666666]\n",
    "    ]\n",
    "accu=[ 0.8400530699491413 , 0.8337878676199602,0.8261222082995504,0.8130021375396181]\n",
    "\n",
    "\n",
    "acc_rate1=[[.2056,.1792,.1407,.1098],\n",
    "        [.1198,.1386,.1402,.1567],\n",
    "        [0.1852,.1717,.1416,.1245],\n",
    "        [.0991,.1040,.1139,.1114],\n",
    "        [.2722,.2425,.2178,.1856],\n",
    "        [.0933,.0933,.1333,.140], \n",
    "       [.0608,.0869,.0521,.0782]]\n",
    "acc_rate=np.transpose(acc_rate1)\n",
    "print(acc_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,2,4]\n",
    "r=[1,3,5,6]\n",
    "\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "sizes=[9211, 4356, 11678,1220, 404, 150,115]\n",
    "for i in range(4):\n",
    "    for j in range(7):\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "            \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu)\n",
    "\n",
    "#adult bilal prec rec acc\n",
    "#svm\n",
    "\n",
    "# [0.7557969195289201, 0.7631586250007302, 0.7792943713492614, 0.7885337390408154] \n",
    "# [0.5589573524287901, 0.5709882640202791, 0.5659744764159914, 0.5683820840757438]\n",
    "# [0.8400530699491413, 0.8337878676199602, 0.8261222082995504, 0.8130021375396181]\n",
    "# #rf\n",
    "# [0.8089992149424856, 0.8173659135858473, 0.8327443873319521, 0.8415342915707418] \n",
    "# [0.6089239165196478, 0.6117545470966688, 0.6006114660644898, 0.6010155883037239] \n",
    "# [0.8586275521485959, 0.8502985184639198, 0.8383577799071276, 0.8238372521559667]\n",
    "# #lr\n",
    "# [0.7588199874277824, 0.7653398213185145, 0.7771816275991712, 0.7862410667954196]\n",
    "# [0.5628480468405138, 0.5661828580849296, 0.5607706794147472, 0.5655577130781149]\n",
    "# [0.8410849856268888, 0.8333456180437827, 0.8232475860543967, 0.812633596226137]\n",
    "# #nn\n",
    "# [0.7707761745753671, 0.7765637892692444, 0.7883425945818253, 0.7970376865869716] \n",
    "# [0.5930559640540808, 0.6018300246172187, 0.5928873076811976, 0.5933826815810495]\n",
    "# [0.8462445640156262, 0.8383577799071276, 0.8270067074519054, 0.8151396771578094]\n",
    "\n",
    "[0.7557969195289201, 0.7631586250007302, 0.7792943713492614, 0.7885337390408154] \n",
    "[0.5589573524287901, 0.5709882640202791, 0.5659744764159914, 0.5683820840757438] \n",
    "[0.8400530699491413, 0.8337878676199602, 0.8261222082995504, 0.8130021375396181]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_rf(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    Y_train.reset_index(drop=True, inplace=True)\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    sens=['s_male','s_female']\n",
    "    print(sens[0],sens[1],X_train.shape[0])\n",
    "    print(sens[0],sens[1],X_train[['s_male']].shape[0])\n",
    "    print(sens[0],sens[1],X_train.loc[3,['s_male']])\n",
    "    import random\n",
    "#     for i in range(X_train.shape[0]):\n",
    "#         print(X_train.loc[i,['s_male']])\n",
    "        \n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    for i in range(X_train.shape[0]):\n",
    "        p=random.randint(0,1)\n",
    "            #q=random.randint(2,6)\n",
    "        \n",
    "        if p==0:\n",
    "            X_train.loc[i,sens[0]]=1\n",
    "#                 if j ==q:\n",
    "#                     X_train.loc[i,sens[p]]=1    \n",
    "#                 if j!=p and j!=q:\n",
    "#                     X_train.loc[i,sens[j]]=0\n",
    "\n",
    "            X_train.loc[i,sens[1]]=0\n",
    "        else:\n",
    "            X_train.loc[i,sens[0]]=0\n",
    "#                 if j ==q:\n",
    "#                     X_train.loc[i,sens[p]]=1    \n",
    "#                 if j!=p and j!=q:\n",
    "#                     X_train.loc[i,sens[j]]=0\n",
    "            \n",
    "            X_train.loc[i,sens[1]]=1\n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "#     from sklearn.svm import SVC\n",
    "#     svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=64, random_state=0)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    rf.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(rf.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=rf.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=rf.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=rf.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "X_test,Y_test_pred,Y_test,e = adult_rf(Data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "sens=X_test[['s_male', 's_female']]\n",
    "\n",
    "sensitive = sens.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    ".0002 0.8435\n",
    "\n",
    ".0005 0.8438\n",
    "\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without accuracy ---> 2\n",
    "def main_tt(datauc,datax, y_test, y_test_pred,e): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    data_uc = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data_uc[j][i]= datauc.iloc[j,i]\n",
    "                if data_uc[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]    \n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data_uc[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"SVM accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    \n",
    "    \n",
    "#     delta1=[.70,.75,.80,.85,.90,.95]\n",
    "    #gamma=.05,.06,.07\n",
    "    #delta1=[.80,.85,.90,.95]\n",
    "# (for reproducibility)  \n",
    "\n",
    "# delta1=[.8], gama=[.1], epsilon=[.05]  \n",
    "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
    " \n",
    "#     delta1=np.arange(1,.79,-.01)\n",
    "    \n",
    "#     gama=[.05,.1,.15,.2,.25]\n",
    "#     epsilon=[.01,.02,.05,.1,.15,.20,.25,.30,.35,.40,.50]\n",
    "\n",
    "#ADULT ZAFAR =? epsilon=[0.088 ,0.1656, 0.168,  0.211, 0.251 ] \n",
    " \n",
    "#agarwal=> epsilon=[ 0.071, 0.1271, 0.2437, 0.27 ]\n",
    "    '''\n",
    "    gamma2=[[0.0964, 0.1998, 0.1657, 0.24, 0.2326, 0.1467, 0.1391] ,\n",
    "    [0.1026, 0.1659, 0.14257, 0.1533, 0.2054, 0.1573, 0.1130],\n",
    "    [0.1255, 0.1104, 0.1123, 0.0666, 0.1460, 0.1409, 0.0956],\n",
    "    [0.1124, 0.0637, 0.0789, 0.0466, 0.0841, 0.0868, 0.0695]]\n",
    "    gamma=np.zeros((4,7),dtype=float)\n",
    "    to=[1,0,2,5,4,3,6]\n",
    "    k=0\n",
    "    for i in range(7):\n",
    "        for j in range(4):\n",
    "            gamma[j][i]=gamma2[j][to[k]]\n",
    "        k=k+1\n",
    "    print(gamma)    \n",
    "    alpha=[[1,1,1,1,1,1,1]]\n",
    "    '''\n",
    "    #gama=[0.0869, 0.0521,0.0782, 0.0608,0.0434, 0.1,0.069,0.0434,0.034]\n",
    "    epsilon=[.01]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "#     for delta in delta1:\n",
    "    #4 gamma=[0.175442,    0.142103, 0.166039,    0.164754,  0.153465,    0.14,  0.104348   ]\n",
    "\n",
    "    #1 gamma=[0.259147,   0.0730028, 0.210139, 0.0893443, 0.306931, 0.0933333,  0.0347826]\n",
    "    #gamma=[0.196178,0.126722,   0.179654, 0.140164,     0.153465,   0.133333,  0.0695652]\n",
    "    '''\n",
    "    #agarwal\n",
    "    gamma2=  [[0.175442, 0.196178, 0.255673, 0.259147],\n",
    "      [0.142103 ,0.126722 ,0.0766758 ,0.0730028],\n",
    "      [ 0.166039 , 0.179654,  0.208084,  0.210139],\n",
    "      [0.164754 , 0.140164 , 0.101639 , 0.0893443],\n",
    "      [0.153465 , 0.153465,  0.287129 , 0.306931],\n",
    "      [0.14, 0.133333  ,0.0933333 , 0.0933333],\n",
    "      [0.104348, 0.0695652,0.0434783,0.0347826]]\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #agar\n",
    "    # gamma2=[[0.175442], [0.142103],[0.166039],[0.164754],[0.153465],[0.14],[0.104348]]\n",
    "    \n",
    "    #gamma2=[[0.175442], [0.142103],[0.166039],[0.164754],[0.153465],[0.14],[0.104348]]\n",
    "    \n",
    "    \n",
    "    #bilal\n",
    "   # gamma2=[[.109868],[.15679],[.124507],[.111475],[.185643],[.140],[.0782608]]\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "     #bilal\n",
    "    gamma2=[[ 7.73645546,  8.12672176,  8.99908173, 10.30762167, 11.98347107, 13.08539945,\n",
    "     13.86593205, 14.09550046, 14.02662994, 15.22038567, 15.6795225 ]\n",
    "    ,[26.09922918, 25.51297362 ,24.15590055, 22.42970362 ,20.56237108 ,19.45499946\n",
    "     ,17.92422104 ,16.13288459, 14.07013354, 12.202801,   10.98686353]\n",
    "    ,[ 9.33333333,  9.33333333  ,8.66666667,  8.0      ,   9.33333333 , 9.33333333\n",
    "      ,9.33333333 , 9.33333333 ,13.33333333 ,11.33333333 ,14.0        ]\n",
    "    ,[29.7029703  ,29.45544554 ,27.97029703 ,27.47524752 ,27.22772277 ,25.24752475\n",
    "     ,24.25742574 ,24.25742574 ,21.78217822 ,19.30693069, 18.56435644]\n",
    "    ,[ 9.42622951 , 9.50819672 ,10.08196721 ,10.24590164  ,9.91803279, 10.08196721\n",
    "     ,10.40983607 ,10.98360656 ,11.39344262, 11.39344262 ,11.14754098]\n",
    "    ,[6.08695652 ,4.34782609 ,4.34782609 ,5.2173913,  6.08695652 ,7.82608696\n",
    "     ,8.69565217 ,6.08695652 ,5.2173913  ,6.95652174 ,7.82608696]\n",
    "    ,[21.27932865 ,20.9796198  ,20.23462922 ,19.36119198 ,18.5305703,  18.1024148\n",
    "     ,17.1775989 , 15.81606439, 14.16338414, 13.23000514 ,12.45076212]]\n",
    "    \n",
    "    gamma2=[[.07736455,.1198347107,.138659,.140266,.15679],\n",
    "[.26099,.2056237108,.179242,.140701,.109868],\n",
    "[.09333,.0933333,.093333,.13333,.140], \n",
    "[.297029,.27227,.2425742,.217821,.185643],\n",
    "[.097029,.099180,.104098,.11393,.111475],\n",
    "[.0608695652,.0608695,.086956,.052173,.0782608],\n",
    "[.21212793,0.185220071930125,.17177,.14163,.124507]\n",
    "]\n",
    "    gamma=np.transpose(gamma2)\n",
    "    '''\n",
    "\n",
    "#     gamma=[[0.30355010313755293, 0.10743801652892562, 0.252269224182223, 0.13278688524590163, 0.3118811881188119, 0.1, 0.13043478260869565]\n",
    "# ]\n",
    "    '''\n",
    "    alpha=[[1,1,1,1,1,1,1],[.1,1,1,1,1,1,1], [.01,1,1,1,1,1,1],[.001,1,1,1,1,1,1],\n",
    "           [1,.1,1,1,1,1,1], [1,.01,1,1,1,1,1],[1,.001,1,1,1,1,1],\n",
    "           [1,1,.1,1,1,1,1], [1,1,.01,1,1,1,1],[1,1,.001,1,1,1,1],\n",
    "           [1,1,1,.1,1,1,1], [1,1,1,.01,1,1,1],[1,1,1,.001,1,1,1],\n",
    "           [1,1,1,1,.1,1,1], [1,1,1,1,.01,1,1,],[1,1,1,1,.001,1,1],\n",
    "           [1,1,1,1,1,.1,1], [1,1,1,1,1,.01,1],[1,1,1,1,1,.001,1],\n",
    "           [1,1,1,1,1,1,.1], [1,1,1,1,1,1,.01],[1,1,1,1,1,1,.001],\n",
    "        [.1,.1,1,1,1,1,1],[.01,.01,1,1,1,1,1], [.001,.001,1,1,1,1,1],[.001,.01,1,1,1,1,1],[.001,.1,1,1,1,1,1],\n",
    "         [.01,.1,1,1,1,1,1] ]\n",
    "    '''  \n",
    "     #alpha=[[1,1,1,1,1,1,1], [1,1,1,1,.1,1,1], [1,1,1,1,.01,1,1,],[1,1,1,1,.001,1,1] ]         \n",
    "    '''\n",
    "    alpha=[[1,1,1,1,1,1,1], [1,1,1,1,.01,1,1], [.1,1,1,1,.01,1,1,],[1,.1,1,1,.01,1,1],[1,1,.01,1,.01,1,1], [1,1,.1,1,.1,1,1], [.1,1,.01,1,.01,1,1], [.01,1,.1,1,.1,1,1] ]        \n",
    "    '''       \n",
    "           #alpha=[90,40,100,10,4,1,10]\n",
    "    #alpha=[ 9211,  4356, 11678,  1220,   404,   150 ,  115]\n",
    "    a=0\n",
    "    '''\n",
    "    #LP-5\n",
    "    gamma=[[0.2591466724568451, 0.07392102846648302, 0.21013872238396986, 0.08934426229508197, 0.3069306930693069, 0.09333333333333334, 0.06956521739130435],\n",
    "[0.24025621539463685, 0.09182736455463728, 0.20106182565507794, 0.10491803278688525, 0.27970297029702973, 0.11333333333333333, 0.06086956521739131],\n",
    "[0.2213657583324286, 0.10996326905417815, 0.191984928926186, 0.11967213114754098, 0.25, 0.12666666666666668, 0.08695652173913043],\n",
    "[0.2024753012702204, 0.1283287419651056, 0.18282240109607809, 0.13524590163934427, 0.22277227722772278, 0.14, 0.11304347826086956],\n",
    "[0.18358484420801216, 0.14646464646464646, 0.17374550436718617, 0.15, 0.19306930693069307, 0.15333333333333332, 0.1391304347826087],\n",
    "[0.16469438714580392, 0.16483011937557393, 0.16466860763829422, 0.16475409836065574, 0.16584158415841585, 0.16666666666666666, 0.16521739130434782]]\n",
    "    alpha=[[1,1,1,1,1,1,1]]\n",
    "    '''\n",
    "\n",
    "    #agarwal\n",
    "    '''\n",
    "    gamma2=    [[0.175442, 0.196178, 0.255673, 0.259147],\n",
    "                [0.142103,0.126722,0.0766758,0.0730028],\n",
    "                [0.166039,0.179654,0.208084,0.210139],\n",
    "                [0.164754,0.140164,0.101639,0.0893443],\n",
    "                [0.153465,0.153465,0.287129,0.306931],\n",
    "                [0.14,0.133333,0.0933333,0.0933333],\n",
    "                [0.104348,0.0695652,0.0434783,0.0347826]]\n",
    "                \n",
    "    gamma=np.transpose(gamma2)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #\n",
    "    gamma=[[0.143,  0.0594, 0.1227, 0.0663, 0.1336, 0.04 ,  0.026 ],\n",
    " [0.1061 ,0.0463 ,0.0911 ,0.0524, 0.1113 ,0.0266, 0.026 ],\n",
    " [0.0776 ,0.0525 ,0.0703 ,0.0639, 0.0866, 0.0333, 0.0347],\n",
    " [0.0772, 0.0757 ,0.0753, 0.0827, 0.094,  0.0933, 0.0782]] \n",
    "    alpha=[[1,1,1,1,1,1,1]]\n",
    "    '''\n",
    "    \n",
    "     #adult LP4 figure varying beta\n",
    "    '''\n",
    "    gamma=[[0.02,.02,.02,.02,.02,.02,.02 ],\n",
    "           [0.025,.025,.025,.025,.025,.025,.025 ],\n",
    "           [0.05,.05,.05,.05,.05,.05,.05 ],          \n",
    "        [0.10,.10,.10,.10,.10,.10,.10 ],\n",
    " [.12 ,.12 ,.12 ,.12,.12 ,.12 ,.12 ],\n",
    " [.14 ,.14 ,.14 ,.14,.14 ,.14 ,.14 ],\n",
    " [.16 ,.16 ,.16 ,.16,.16 ,.16 ,.16 ],\n",
    " [.18 ,.18 ,.18 ,.18,.18 ,.18 ,.18 ],\n",
    " [.20 ,.20 ,.20 ,.20,.20 ,.20 ,.20 ],\n",
    "           [0.25,.25,.25,.25,.25,.25,.25 ],\n",
    "           [0.3,.3,.3,.3,.3,.3,.3 ],\n",
    "           [0.35,.35,.35,.35,.35,.35,.35 ]]\n",
    "    '''\n",
    "    #bilal\n",
    "    gamma2=[[.20,.16,.1407,.10],\n",
    "        [.20,.16,.1402,.10]]\n",
    "       \n",
    "    gamma=np.transpose(gamma2)\n",
    "    alpha=[[1,1]]\n",
    "    epsilon=[.01]\n",
    "    t=0\n",
    "    #for t in range(gamma.shape[0]):\n",
    "    #for t in range(28):\n",
    "    for new in range(4):\n",
    "        k=0\n",
    "        for t in range(1):\n",
    "            for eps in epsilon:\n",
    "                u1,u2=min_sum_lpca(data,gamma[new],eps,e,alpha[t])\n",
    "                #######################Disp_impact#######################  \n",
    "                print(\"gamma-epsilon-delta\",gamma[new],eps)\n",
    "                accu_all=[]\n",
    "                DP_all=[]\n",
    "                precision_all=[]\n",
    "                recall_all=[]\n",
    "                ar_all=[]\n",
    "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "                count=0\n",
    "                print(\"<--------------------------------------->\")\n",
    "                print(\"iteration t\",k)\n",
    "                k=k+1\n",
    "        #                 for alpha in np.arange(0,1.05,0.05):\n",
    "        #                     print(\"alpha: \",alpha)\n",
    "        #                     for i in range(n):\n",
    "\n",
    "        #                         z=random()\n",
    "        #                         if z < alpha:\n",
    "        #                                fi[i]= u1[i] \n",
    "\n",
    "        #                         else:\n",
    "        #                                fi[i]= r2[i]\n",
    "\n",
    "                for i in range(n):\n",
    "                     fi[i] = u1[i]\n",
    "\n",
    "\n",
    "                for j in range(s):\n",
    "                    print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "                    TP=0\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TN=0\n",
    "                    precision=0\n",
    "                    recall=0\n",
    "                    for i in range(n):\n",
    "                         if data_uc[j][i]== 1 :                        \n",
    "                            if fi[i]==1 and r[i]==1:\n",
    "                                TP=TP+1\n",
    "                            if fi[i]==1 and r[i]==-1:\n",
    "                                FP=FP+1 \n",
    "                            if fi[i]==-1 and r[i]==1:\n",
    "                                FN=FN+1\n",
    "                            if fi[i]==-1 and r[i]==-1:\n",
    "                                TN=TN+1    \n",
    "                    if TP+FP !=0:\n",
    "                        precision=float(TP/(TP+FP))\n",
    "                    #print(\"precision\",precision)\n",
    "                    if TP+FN !=0:    \n",
    "                        recall=float(TP/(TP+FN))\n",
    "                    #print(\"recall\",recall)\n",
    "\n",
    "                    precision_all.append(precision)\n",
    "                    recall_all.append(recall)\n",
    "                    #print(\"TP,FP,TN,FN\")\n",
    "                    #print(TP,FP,TN,FN)\n",
    "\n",
    "                    a=0\n",
    "                    b=0\n",
    "                    acc1=0\n",
    "                    acc2=0\n",
    "                    for i in range(n):\n",
    "                            if data_uc[j][i]== 1 :\n",
    "                                a=a+1\n",
    "                                if fi[i]==1:\n",
    "                                     acc1=acc1+1 \n",
    "\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                    a1=float(acc1/a)\n",
    "\n",
    "\n",
    "\n",
    "        #                         print(a)\n",
    "        #                         print(acc1)\n",
    "        #                         print(a1)\n",
    "                    ar_all.append(a1)\n",
    "\n",
    "                count = count+1\n",
    "                maxi=max(ar_all)\n",
    "                mini= min(ar_all)\n",
    "                DP=float(maxi-mini)\n",
    "                print(\"individual acceptance rates\")\n",
    "                print(ar_all)\n",
    "                print(\"individul precision\")\n",
    "                print(precision_all)\n",
    "                print(\"individual recall\")\n",
    "                print(recall_all)\n",
    "                print(\"DP all\")\n",
    "                print(DP)\n",
    "                f_acc=0\n",
    "                for i in range(n):\n",
    "                     if fi[i] == r[i]:\n",
    "                            f_acc=f_acc+1\n",
    "                f_acc_l=float((f_acc*100)/n) \n",
    "\n",
    "        #######################################################################33   \n",
    "\n",
    "        #                         print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                TP=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TN=0\n",
    "                precision=0\n",
    "                recall=0\n",
    "                accu=0\n",
    "                for i in range(n):\n",
    "                        if fi[i]==1 and r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        if fi[i]==1 and r[i]==-1:\n",
    "                            FP=FP+1 \n",
    "                        if fi[i]==-1 and r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        if fi[i]==-1 and r[i]==-1:\n",
    "                            TN=TN+1    \n",
    "\n",
    "                if TP+FP!=0:\n",
    "                    precision=float(TP/(TP+FP))\n",
    "                print(\"precision all\",precision)\n",
    "                if TP+FN!=0:\n",
    "                    recall=float(TP/(TP+FN))\n",
    "\n",
    "\n",
    "                print(\"recall all\",recall)\n",
    "                accu=float((TP+TN)/(TP+FN+TN+FP))\n",
    "\n",
    "\n",
    "                print(\"accuracy all\",accu)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"TP,FP,TN,FN\")\n",
    "                print(TP,FP,TN,FN)\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "\n",
    "\n",
    "    print(\"<--------------------------------------->\")\n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_rf(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    Y_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    X_test1=X_test.copy(deep=True)\n",
    "    X_test2=X_test.copy(deep=True)\n",
    "    print(X_test2['s_male'].value_counts())\n",
    "    Y_test.reset_index(drop=True, inplace=True)\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "    sens=['s_male','s_female']\n",
    "    print(sens[0],sens[1],X_train.shape[0])\n",
    "    print(sens[0],sens[1],X_train[['s_male']].shape[0])\n",
    "    print(sens[0],sens[1],X_train.loc[3,['s_male']])\n",
    "    \n",
    "    import random\n",
    "#     for i in range(X_train.shape[0]):\n",
    "#         print(X_train.loc[i,['s_male']])\n",
    "        \n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    for i in range(X_test1.shape[0]):\n",
    "        p=random.randint(0,1)\n",
    "            #q=random.randint(2,6)\n",
    "        \n",
    "        if p==0:\n",
    "            X_test1.loc[i,sens[0]]=1\n",
    "#                 if j ==q:\n",
    "#                     X_train.loc[i,sens[p]]=1    \n",
    "#                 if j!=p and j!=q:\n",
    "#                     X_train.loc[i,sens[j]]=0\n",
    "\n",
    "            X_test1.loc[i,sens[1]]=0\n",
    "        else:\n",
    "            X_test1.loc[i,sens[0]]=0\n",
    "#                 if j ==q:\n",
    "#                     X_train.loc[i,sens[p]]=1    \n",
    "#                 if j!=p and j!=q:\n",
    "#                     X_train.loc[i,sens[j]]=0\n",
    "            \n",
    "            X_test1.loc[i,sens[1]]=1\n",
    "        \n",
    "        \n",
    "    print(X_test2['s_male'].value_counts())\n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "#     from sklearn.svm import SVC\n",
    "#     svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=64, random_state=0)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    rf.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(rf.score(X_test1, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=rf.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=rf.predict(X_test1)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=rf.predict_proba(X_test1)\n",
    "    print(e)\n",
    "    return X_test2,X_test1,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "X_test2,X_test,Y_test_pred,Y_test,e = adult_rf(Data_c , r)\n",
    "\n",
    "\n",
    "#X_test1 corrupt\n",
    "sens=X_test2[['s_male', 's_female']]\n",
    "\n",
    "sensitive_uc = sens.T\n",
    "\n",
    "\n",
    "sens2=X_test[['s_male', 's_female']]\n",
    "\n",
    "sensitive_c = sens2.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "# .0002 0.8435\n",
    "\n",
    "# .0005 0.8438\n",
    "\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main_tt(sensitive_uc,sensitive_c, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prec=[[0.8262017960908611, 0.6065259117082533, 0.803422756706753, 0.5833333333333334, 0.5779816513761468, 0.3333333333333333, 0.625],\n",
    "[0.8527272727272728, 0.5572139303482587, 0.8169576059850374, 0.40476190476190477, 0.4639175257731959, 0.26666666666666666, 0.5],\n",
    "[0.8965250965250965, 0.5360655737704918, 0.8542044767090139, 0.2463768115942029, 0.3793103448275862, 0.21052631578947367, 0.625],\n",
    "[0.9216634429400387, 0.501466275659824, 0.8451479697178252, 0.22818791946308725, 0.3, 0.17391304347826086, 0.45454545454545453]]\n",
    "\n",
    "rec=[[0.5593705293276109, 0.6752136752136753, 0.5896130346232179, 0.43209876543209874, 0.5, 0.3333333333333333, 0.3333333333333333],\n",
    "[0.5032188841201717, 0.717948717948718, 0.5560081466395111, 0.3148148148148148, 0.35714285714285715, 0.26666666666666666, 0.3333333333333333],\n",
    "[0.41523605150214593, 0.6987179487179487, 0.4792939579090292, 0.20987654320987653, 0.2619047619047619, 0.26666666666666666, 0.3333333333333333],\n",
    "[0.34084406294706726, 0.7307692307692307, 0.41683638832315, 0.20987654320987653, 0.19047619047619047, 0.26666666666666666, 0.3333333333333333]]\n",
    "\n",
    "accu=[0.8586275521485959 , 0.8502985184639198, 0.8383577799071276 , 0.8238372521559667]\n",
    "\n",
    "acc_rate1=[[.2056,.1792,.1407,.1098],\n",
    "        [.1198,.1386,.1402,.1567],\n",
    "        [0.1852,.1717,.1416,.1245],\n",
    "        [.0991,.1040,.1139,.1114],\n",
    "        [.2722,.2425,.2178,.1856],\n",
    "        [.0933,.0933,.1333,.140], \n",
    "       [.0608,.0869,.0521,.0782]]\n",
    "acc_rate=np.transpose(acc_rate1)\n",
    "print(acc_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,2,4]\n",
    "r=[1,3,5,6]\n",
    "\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "sizes=[9211, 4356, 11678,1220, 404, 150,115]\n",
    "for i in range(4):\n",
    "    for j in range(7):\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "            \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu)\n",
    "[0.8089992149424856, 0.8173659135858473, 0.8327443873319521, 0.8415342915707418] \n",
    "[0.6089239165196478, 0.6117545470966688, 0.6006114660644898, 0.6010155883037239] \n",
    "[0.8586275521485959, 0.8502985184639198, 0.8383577799071276, 0.8238372521559667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[0.7557969195289201, 0.7631586250007302, 0.7792943713492614, 0.7885337390408154] \n",
    "[0.5589573524287901, 0.5709882640202791, 0.5659744764159914, 0.5683820840757438]\n",
    "[0.8400530699491413, 0.8337878676199602, 0.8261222082995504, 0.8130021375396181]\n",
    "\n",
    "[0.8089992149424856, 0.8173659135858473, 0.8327443873319521, 0.8415342915707418] \n",
    "[0.6089239165196478, 0.6117545470966688, 0.6006114660644898, 0.6010155883037239] \n",
    "[0.8586275521485959, 0.8502985184639198, 0.8383577799071276, 0.8238372521559667]\n",
    "#lr\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_lr(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "#     from sklearn.svm import SVC\n",
    "#     svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    lr.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(lr.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(lr.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=lr.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=lr.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=lr.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr\n",
    "X_test,Y_test_pred,Y_test,e = adult_lr(Data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "sens=X_test[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
    "\n",
    "sensitive = sens.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec=[[0.7739038563127311, 0.5681381957773513, 0.7525439407955596, 0.5, 0.5963302752293578, 0.3125, 0.5714285714285714],\n",
    "[0.7957575757575758, 0.5223880597014925, 0.7625935162094764, 0.3333333333333333, 0.4948453608247423, 0.25, 0.5555555555555556],\n",
    "[0.8302469135802469, 0.5081967213114754, 0.7906836055656382, 0.2391304347826087, 0.42528735632183906, 0.2, 0.625],\n",
    "[0.8617021276595744, 0.4809384164222874, 0.7935306262904336, 0.22818791946308725, 0.2875, 0.17391304347826086, 0.45454545454545453]\n",
    "     ]\n",
    "rec=[[0.5239628040057225, 0.6324786324786325, 0.5522742701968771, 0.37037037037037035, 0.5158730158730159, 0.3333333333333333, 0.26666666666666666],\n",
    "[0.4695994277539342, 0.6730769230769231, 0.5190088255261371, 0.25925925925925924, 0.38095238095238093, 0.26666666666666666, 0.3333333333333333],\n",
    "[0.38483547925608014, 0.6623931623931624, 0.44365241004752204, 0.2037037037037037, 0.29365079365079366, 0.26666666666666666, 0.3333333333333333],\n",
    "[0.3186695278969957, 0.7008547008547008, 0.39137813985064496, 0.20987654320987653, 0.18253968253968253, 0.26666666666666666, 0.3333333333333333]\n",
    "    ]\n",
    "accu=[ 0.8410849856268888, 0.8333456180437827, 0.8232475860543967, 0.812633596226137]\n",
    "\n",
    "\n",
    "acc_rate1=[[.2056,.1792,.1407,.1098],\n",
    "        [.1198,.1386,.1402,.1567],\n",
    "        [0.1852,.1717,.1416,.1245],\n",
    "        [.0991,.1040,.1139,.1114],\n",
    "        [.2722,.2425,.2178,.1856],\n",
    "        [.0933,.0933,.1333,.140], \n",
    "       [.0608,.0869,.0521,.0782]]\n",
    "acc_rate=np.transpose(acc_rate1)\n",
    "print(acc_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,2,4]\n",
    "r=[1,3,5,6]\n",
    "\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "sizes=[9211, 4356, 11678,1220, 404, 150,115]\n",
    "for i in range(4):\n",
    "    for j in range(7):\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "            \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu)\n",
    "\n",
    "[0.7588199874277824, 0.7653398213185145, 0.7771816275991712, 0.7862410667954196]\n",
    "[0.5628480468405138, 0.5661828580849296, 0.5607706794147472, 0.5655577130781149]\n",
    "[0.8410849856268888, 0.8333456180437827, 0.8232475860543967, 0.812633596226137]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#nn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_nn(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "#     from sklearn.svm import SVC\n",
    "#     svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    nn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                        hidden_layer_sizes=(30, 2), random_state=0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    nn.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(nn.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(nn.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=nn.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=nn.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=nn.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn\n",
    "X_test,Y_test_pred,Y_test,e = adult_nn(Data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "sens=X_test[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
    "\n",
    "sensitive = sens.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nn\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec=[[0.7855256207078711, 0.5930902111324377, 0.7654949121184089, 0.5655737704918032, 0.5871559633027523, 0.23076923076923078, 0.625],\n",
    "[0.8072727272727273, 0.5472636815920398, 0.771571072319202, 0.42857142857142855, 0.5257731958762887, 0.3125, 0.5555555555555556],\n",
    "[0.8432432432432433, 0.5229508196721312, 0.7997580157289776, 0.2971014492753623, 0.4482758620689655, 0.2631578947368421, 0.5],\n",
    "[0.8689320388349514, 0.4970674486803519, 0.8045423262216105, 0.21476510067114093, 0.3157894736842105, 0.17391304347826086, 0.45454545454545453]]\n",
    "rec=[[0.5318311874105865, 0.6602564102564102, 0.5617786829599457, 0.42592592592592593, 0.5079365079365079, 0.2, 0.3333333333333333],\n",
    "[0.47639484978540775, 0.7051282051282052, 0.5251188051595383, 0.3333333333333333, 0.40476190476190477, 0.3333333333333333, 0.3333333333333333],\n",
    "[0.3905579399141631, 0.6816239316239316, 0.4487440597420231, 0.25308641975308643, 0.30952380952380953, 0.3333333333333333, 0.26666666666666666],\n",
    "[0.32010014306151646, 0.7243589743589743, 0.3968092328581127, 0.19753086419753085, 0.19047619047619047, 0.26666666666666666, 0.3333333333333333]]\n",
    "accu=[0.8462445640156262,0.8383577799071276,0.8270067074519054,0.8151396771578094]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc_rate1=[[.2056,.1792,.1407,.1098],\n",
    "        [.1198,.1386,.1402,.1567],\n",
    "        [0.1852,.1717,.1416,.1245],\n",
    "        [.0991,.1040,.1139,.1114],\n",
    "        [.2722,.2425,.2178,.1856],\n",
    "        [.0933,.0933,.1333,.140], \n",
    "       [.0608,.0869,.0521,.0782]]\n",
    "acc_rate=np.transpose(acc_rate1)\n",
    "print(acc_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,2,4]\n",
    "r=[1,3,5,6]\n",
    "\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "sizes=[9211, 4356, 11678,1220, 404, 150,115]\n",
    "for i in range(4):\n",
    "    for j in range(7):\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "            \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu)\n",
    "\n",
    "[0.7707761745753671, 0.7765637892692444, 0.7883425945818253, 0.7970376865869716] \n",
    "[0.5930559640540808, 0.6018300246172187, 0.5928873076811976, 0.5933826815810495]\n",
    "[0.8462445640156262, 0.8383577799071276, 0.8270067074519054, 0.8151396771578094]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# padala final\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlapping paper final\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LP-5\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final agar1\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final bilal1\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agar1\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agar2\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bilal1>\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilal2>\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agar test\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
