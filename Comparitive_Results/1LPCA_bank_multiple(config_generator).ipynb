{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest For Bank\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def Bank_rf(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "#     from sklearn.svm import SVC\n",
    "#     svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=150, max_depth=None, min_samples_split=30, random_state=0)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    rf.fit(X_train, Y_train)\n",
    "    print('The accuracy of the RF classifier on training data is {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "    print('The accuracy of the RF classifier on test data is {:.2f}'.format(rf.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=rf.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=rf.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=rf.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(datax, y_test, y_test_pred,e): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        if TP+FP!= 0:\n",
    "            prec= float(TP/(TP+FP))\n",
    "        if TP+FN!=0:\n",
    "            reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"Random Forest---------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "  \n",
    " \n",
    "    \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    \n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "#COMMENT   : \"ar\" #############use this predicted RandomForet accptance rate(config) hardcoded or\n",
    "#can pass it through LPCA as lpca() \n",
    "#above ar: Random forest acceptance rate is use as beta_initial/beta (named as beata_initial in paper)\n",
    "######################################RF acceptance rate as beta_initial #############   \n",
    "    beta_initial=ar\n",
    "\n",
    "########################################################################################      \n",
    "    \n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"Random Forest accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "    if TP+FP!=0 :   \n",
    "        prec= float(TP/(TP+FP))\n",
    "    if TP+FN!=0:    \n",
    "        reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(\"prec--reca--accur\")\n",
    "    print(prec,reca,accur)\n",
    "    ########################COMMENTS\n",
    "######################SET input parameters of users choice beta_ converge,  \n",
    "\n",
    "#(beta_converge, alpha and epsilon are the parameters of LPCA ) \n",
    "# alpha=1 use initial predicted(beta configs) by classifier (RF), at alpha=0 converges to Least DDP config at beta_converge\n",
    "#Example for beta_converge = [0.048,.085,.09,.15,.25,.32]\n",
    "    \n",
    "    \n",
    "    \n",
    "    epsilon=[.005,.01]\n",
    "    \n",
    "    beta_converge = [0.048,.085,.09,.15,.25,.32]\n",
    "    #beta_converge = [.08,.09]\n",
    "    alpha = [1,.8,.6,.4,.2,0]\n",
    "    \n",
    "   \n",
    "    fi= np.zeros(n,dtype=int) \n",
    "    \n",
    "    t=0\n",
    "    #gamma  = [0.27979274611398963, 0.0718288334182374, 0.07343212490076739, 0.10702734489855925, 0.06472727272727273, 0.043]\n",
    "\n",
    "   \n",
    "  \n",
    "    #COMMENT\n",
    "    #beta_initial(passed in min_sum_lpca()) \n",
    "    #mentioned in min_sum_lpca():function cell below    \n",
    "    #beta_initial = [0.27979274611398963, 0.0718288334182374, 0.07343212490076739, 0.10702734489855925, 0.06472727272727273, 0.043]\n",
    "\n",
    "\n",
    "    for eps in epsilon:\n",
    "        for beta_avg in beta_converge:\n",
    "            print(\"----------------This is for covergence at beta = \",beta_avg, \" ----------------\")\n",
    "            for a in alpha:\n",
    "               \n",
    "            ######COMMENT min_sum_lpca()\n",
    "#beta_initial passed in min_sum_lpca() with name beta_initial i.e acc_rate of RF can be paased dynamically\n",
    "            ##parameters\n",
    "                  #data: sensitive sub groups in adult it is 7 dimensional\n",
    "                  #beta_avg (beta^): convergence point from beta_initial(at alpha=1)\n",
    "                  #alpha=0 for minimum DDP achievement\n",
    "                    #eps: to contain config within eps(eps=.005 means achieving DDP<2*eps means <.01 DDP )      \n",
    "\n",
    "                u1,u2 = min_sum_lpca(data,beta_initial,eps,e,beta_avg,a)\n",
    "                #######################Disp_impact#######################  \n",
    "                print(\"alpha, beta_avg\",a,beta_avg)\n",
    "                accu_all=[]\n",
    "                DP_all=[]\n",
    "                precision_all=[]\n",
    "                recall_all=[]\n",
    "                ar_all=[]\n",
    "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "                count=0\n",
    "                print(\"<------epsilon-\",eps,\"-------------------------------->\")\n",
    "                t=t+1\n",
    "                print(\"iteration t\",t)\n",
    "       \n",
    "\n",
    "                for i in range(n):\n",
    "                     fi[i] = u1[i]\n",
    "\n",
    "\n",
    "                for j in range(s):\n",
    "                    print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "                    TP=0\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TN=0\n",
    "                    precision=0\n",
    "                    recall=0\n",
    "                    for i in range(n):\n",
    "                         if data[j][i]== 1 :                        \n",
    "                            if fi[i]==1 and r[i]==1:\n",
    "                                TP=TP+1\n",
    "                            if fi[i]==1 and r[i]==-1:\n",
    "                                FP=FP+1 \n",
    "                            if fi[i]==-1 and r[i]==1:\n",
    "                                FN=FN+1\n",
    "                            if fi[i]==-1 and r[i]==-1:\n",
    "                                TN=TN+1    \n",
    "                    if TP+FP !=0:\n",
    "                        precision=float(TP/(TP+FP))\n",
    "                    #print(\"precision\",precision)\n",
    "                    if TP+FN !=0:    \n",
    "                        recall=float(TP/(TP+FN))\n",
    "                   # print(\"recall\",recall)\n",
    "\n",
    "                    precision_all.append(precision)\n",
    "                    recall_all.append(recall)\n",
    "                    #print(\"TP,FP,TN,FN\")\n",
    "                    #print(TP,FP,TN,FN)\n",
    "\n",
    "                    a=0\n",
    "                    b=0\n",
    "                    acc1=0\n",
    "                    acc2=0\n",
    "                    for i in range(n):\n",
    "                            if data[j][i]== 1 :\n",
    "                                a=a+1\n",
    "                                if fi[i]==1:\n",
    "                                     acc1=acc1+1 \n",
    "\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                    a1=float(acc1/a)\n",
    "\n",
    "\n",
    "\n",
    "        #                         print(a)\n",
    "        #                         print(acc1)\n",
    "        #                         print(a1)\n",
    "                    ar_all.append(a1)\n",
    "\n",
    "                count = count+1\n",
    "                maxi=max(ar_all)\n",
    "                mini= min(ar_all)\n",
    "                DP=float(maxi-mini)\n",
    "                print(\"individual acceptance rates\")\n",
    "                print(ar_all)\n",
    "                print(\"individual precision\")\n",
    "                print(precision_all)\n",
    "                print(\"individual recall\")\n",
    "                print(recall_all)\n",
    "                print(\"DP all\")\n",
    "                print(DP)\n",
    "                f_acc=0\n",
    "                for i in range(n):\n",
    "                     if fi[i] == r[i]:\n",
    "                            f_acc=f_acc+1\n",
    "                f_acc_l=float((f_acc*100)/n) \n",
    "\n",
    "        #######################################################################33   \n",
    "\n",
    "        #                         print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                TP=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TN=0\n",
    "                precision=0\n",
    "                recall=0\n",
    "                accu=0\n",
    "                for i in range(n):\n",
    "                        if fi[i]==1 and r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        if fi[i]==1 and r[i]==-1:\n",
    "                            FP=FP+1 \n",
    "                        if fi[i]==-1 and r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        if fi[i]==-1 and r[i]==-1:\n",
    "                            TN=TN+1    \n",
    "\n",
    "                if TP+FP!=0:\n",
    "                    precision=float(TP/(TP+FP))\n",
    "                print(\"precision all\",precision)\n",
    "                if TP+FN!=0:\n",
    "                    recall=float(TP/(TP+FN))\n",
    "\n",
    "\n",
    "                print(\"recall all\",recall)\n",
    "                accu=float((TP+TN)/(TP+FN+TN+FP))\n",
    "\n",
    "\n",
    "                print(\"accuracy all\",accu)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"TP,FP,TN,FN\")\n",
    "                print(TP,FP,TN,FN)\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "          \n",
    "\n",
    "    print(\"<--------------------------------------->\")\n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################LPCA######CODE######to corverge in given beta_avg setting###########by varying alpha from 1 to 0\n",
    "\n",
    "#data1 is sensitive group in binary matrix sets \n",
    "import time\n",
    "import pulp as p \n",
    "def min_sum_lpca(data1,beta,eps,e,beta_avg,alpha):\n",
    "    import pulp as p \n",
    "    import math\n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    \n",
    "    ################ sorted result\n",
    "    h1=[]\n",
    "    h2=[]\n",
    "    h3=[]\n",
    "    h4=[]\n",
    "    h5=[]\n",
    "    h6=[]\n",
    "   \n",
    "    key1=[]\n",
    "    key2=[]\n",
    "    key3=[]\n",
    "    key4=[]\n",
    "    key5=[]\n",
    "    key6=[]\n",
    "   \n",
    "    cost=np.zeros(n,dtype=int)\n",
    "    data2=np.zeros((m,n),dtype=int)\n",
    "    for i in range(n):\n",
    "        if data1[0][i]==1:            \n",
    "            h1.append(e[i][1])\n",
    "            key1.append(i)\n",
    "\n",
    "        elif data1[1][i]==1:\n",
    "            h2.append(e[i][1])\n",
    "            key2.append(i)\n",
    "            \n",
    "        if data1[2][i]==1:\n",
    "            h3.append(e[i][1])\n",
    "            key3.append(i)\n",
    "            \n",
    "        elif data1[3][i]==1:\n",
    "            h4.append(e[i][1])\n",
    "            key4.append(i)\n",
    "        elif data1[4][i]==1:\n",
    "            h5.append(e[i][1])\n",
    "            key5.append(i)\n",
    "        elif data1[5][i]==1:\n",
    "            h6.append(e[i][1])\n",
    "            key6.append(i)\n",
    "        elif data1[6][i]==1:\n",
    "            h7.append(e[i][1])\n",
    "            key7.append(i)\n",
    "#print(hc)\n",
    "#     print(key1)\n",
    "    \n",
    "    for i in range(1,len(h1)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h1[j-1]<h1[j]:\n",
    "                index=j\n",
    "                var=h1[j]\n",
    "                h1[j]=h1[j-1]\n",
    "                h1[j-1]=var\n",
    "\n",
    "                var2=key1[j]\n",
    "                key1[j]=key1[j-1]\n",
    "                key1[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "\n",
    "    for i in range(1,len(h2)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h2[j-1]<h2[j]:\n",
    "                index=j\n",
    "                var=h2[j]\n",
    "                h2[j]=h2[j-1]\n",
    "                h2[j-1]=var\n",
    "\n",
    "                var2=key2[j]\n",
    "                key2[j]=key2[j-1]\n",
    "                key2[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h3)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h3[j]:\n",
    "                index=j\n",
    "                var=h3[j]\n",
    "                h3[j]=h3[j-1]\n",
    "                h3[j-1]=var\n",
    "\n",
    "                var2=key3[j]\n",
    "                key3[j]=key3[j-1]\n",
    "                key3[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h4)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h4[j-1]<h4[j]:\n",
    "                index=j\n",
    "                var=h4[j]\n",
    "                h4[j]=h4[j-1]\n",
    "                h4[j-1]=var\n",
    "\n",
    "                var2=key4[j]\n",
    "                key4[j]=key4[j-1]\n",
    "                key4[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h5)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h5[j]:\n",
    "                index=j\n",
    "                var=h5[j]\n",
    "                h5[j]=h5[j-1]\n",
    "                h5[j-1]=var\n",
    "\n",
    "                var2=key5[j]\n",
    "                key5[j]=key5[j-1]\n",
    "                key5[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    for i in range(1,len(h6)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h6[j-1]<h6[j]:\n",
    "                index=j\n",
    "                var=h6[j]\n",
    "                h6[j]=h6[j-1]\n",
    "                h6[j-1]=var\n",
    "\n",
    "                var2=key6[j]\n",
    "                key6[j]=key6[j-1]\n",
    "                key6[j-1]=var2\n",
    "            else:\n",
    "                break \n",
    "                \n",
    "#####alpha2 is just another weight influencing parameter for now its neutral with [\"ones\"] vector\n",
    "    alpha2=[1,1,1,1,1,1]            \n",
    "    '''       \n",
    "    #basic1\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "         \n",
    "        data2[0][key1[j]]=(j+1)*alpha[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha[1]\n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)*alpha[2]              \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        data2[3][key4[j]]=(j+1)*alpha[3]\n",
    "        \n",
    "                             \n",
    "    for j in range(len(key5)):               \n",
    "        data2[4][key5[j]]=(j+1)*alpha[4]\n",
    "       \n",
    "    for j in range(len(key6)):\n",
    "        data2[5][key6[j]]=(j+1)*alpha[5]\n",
    "    \n",
    "    #basic2\n",
    "            \n",
    "    '''\n",
    "   \n",
    "\n",
    "    for j in range(len(key1)):    \n",
    "        #data2[0][key1[j]]=((j+1)/((beta[0]*len(key1))*((beta[0]*len(key1))+1)/2)*alpha[0])\n",
    "        \n",
    "        data2[0][key1[j]]=(j+1)*alpha2[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*alpha2[1]\n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)*alpha2[2]                 \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        data2[3][key4[j]]=(j+1)*alpha2[3]                            \n",
    "    for j in range(len(key5)):\n",
    "        data2[4][key5[j]]=(j+1)*alpha2[4]       \n",
    "    for j in range(len(key6)):\n",
    "        data2[5][key6[j]]=(j+1)*alpha2[5]\n",
    "         \n",
    "\n",
    "########################################################################    \n",
    "#sum up the weighted subgroup rank in cost \n",
    "    for j in range(n):\n",
    "        summ=0\n",
    "        for i in range(m):\n",
    "       \n",
    "            summ=summ+data2[i][j] \n",
    "        cost[j]=summ\n",
    "\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    \n",
    "###############################Optimization fuction for LPCA###################\n",
    "# beta_avg(convergence point to achieve least DP at alpha=0   \n",
    "# beta_actual is beta_initial (acceptance rate) config obtaind for each group from random forest prediction)   \n",
    "\n",
    "\n",
    "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
    "    Y=np.zeros(m,dtype=p.LpVariable)\n",
    "    \n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    \n",
    "#sum up the subgroup ranks in cost   \n",
    "    max_size=0\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1 \n",
    "        if count>max_size:\n",
    "            max_size=count\n",
    "        sizes[i]=count\n",
    "    print(sizes)        \n",
    "    \n",
    "    \n",
    "    \n",
    "    beta_initial=beta\n",
    "    #beta_initial = gamma\n",
    "    \n",
    "    select_sizes=np.zeros(m,dtype=int)\n",
    "   \n",
    "    size_final=np.zeros(m,dtype=int)\n",
    "\n",
    "    for i in range(m):\n",
    "        var1 = str(n+100+i)\n",
    "        Y[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Continuous')\n",
    "    \n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "   \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
    "\n",
    "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)])\n",
    "    \n",
    "\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= (Y[i]-eps)*sizes[i]\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= (Y[i]+eps)*sizes[i]\n",
    "    \n",
    "    '''\n",
    "# for minimum ddp at alpa=0 setup (like paper) change (1- alpha) to (alpha) & (alpha) to (1-alpha)    \n",
    "    for i in range(m):\n",
    "            if beta_initial[i] >= beta_avg:\n",
    "\n",
    "                Lp_prob += Y[i] >= (1-alpha)*beta_initial[i] +alpha*beta_avg\n",
    "                Lp_prob += Y[i] <= (1-alpha)*beta_initial[i] +alpha*beta_avg\n",
    "               \n",
    "            else:\n",
    "                Lp_prob += Y[i] >= (1-alpha)*beta_initial[i] + alpha*beta_avg\n",
    "                Lp_prob += Y[i] <= beta_avg   \n",
    "    '''      \n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "            if beta_initial[i] >= beta_avg:\n",
    "\n",
    "                Lp_prob += Y[i] >= (alpha)*beta_initial[i] +(1-alpha)*beta_avg\n",
    "                Lp_prob += Y[i] <= (alpha)*beta_initial[i] +(1-alpha)*beta_avg\n",
    "               \n",
    "            else:\n",
    "                Lp_prob += Y[i] >= (alpha)*beta_initial[i] + (1-alpha)*beta_avg\n",
    "                Lp_prob += Y[i] <= beta_avg               \n",
    "   \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"objective is:\")        \n",
    "    #print(p.value(Lp_prob.objective))\n",
    "    print(\"discripency is:\") \n",
    "    print(p.value(X[n]))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# without accuracy\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "data= pd.read_csv('data/bank_train.csv',skipinitialspace=True)\n",
    "\n",
    "print(data['marital'].value_counts())\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    "\n",
    "#sensitive columns name 0='age',2='marital'\n",
    "\n",
    "data_c = data.drop(columns=['age_group','y'])\n",
    "# print(sens)\n",
    "r=data[['y']]\n",
    "\n",
    "X_test,Y_test_pred,Y_test,e = Bank_rf(data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "print(X_test)\n",
    "print(Y_test_pred)\n",
    "print(Y_test)\n",
    "sens=X_test[['age','marital']]\n",
    "print(sens)\n",
    "p=sens.shape[0]\n",
    "\n",
    "# for i in range(0,p):  \n",
    "#     if r.loc[i,'y'] == 1 :\n",
    "#                r.loc[i,\"y\"] = 1 \n",
    "#     else: \n",
    "#                r.loc[i,\"y\"] = 0 \n",
    "            \n",
    "for i in range(0,p):\n",
    "    if sens.loc[i,'age'] > 60 or sens.loc[i,'age'] < 25 :\n",
    "               sens.loc[i,'age'] = 1 \n",
    "    else :\n",
    "               sens.loc[i,'age'] = 2  \n",
    "            \n",
    "sens1 = pd.get_dummies(sens, columns=['age','marital'], prefix =['a','m'])\n",
    "print(sens1.head())\n",
    "sensitive = sens1.T\n",
    "\n",
    "print(sensitive)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LPCA ranked \n",
    "accu_all,DP_all,acc_rate,alpha,prec,rec = main(sensitive, Y_test, Y_test_pred,e )\n",
    "\n",
    "\n",
    "\n",
    "# Observe group wise acc_rate,precision, recall, DP\n",
    "#eps=.005 ensures DDP<.01\n",
    "#see the the convergence at alpha =0\n",
    "#SEE Optimal group wise acceptance rate/config (individual beta) with varying alpha\n",
    "\n",
    "#observe valid configurations only\n",
    "\n",
    "#optimal before iterations tells the valid configuration on parameters.\n",
    "#undefined ,means invalid configuration on given parameters\n",
    "       #if undefined increase eps from .005 to .01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rate=[[0.27806563039723664, 0.06690439803022584, 0.06853664990738291, 0.10202881505439576, 0.06036363636363636, 0.043478260869565216],\n",
    "[0.24006908462867013, 0.0695364238410596, 0.07078592220164065, 0.09791237871214349, 0.064, 0.08695652173913043],\n",
    "\n",
    "[0.20207253886010362, 0.07216844965189335, 0.07316750463085472, 0.09350191120258747, 0.06836363636363636, 0.08695652173913043],\n",
    "\n",
    "[0.16062176165803108, 0.07480047546272711, 0.07541677692511246, 0.08909144369303146, 0.072, 0.08695652173913043],\n",
    "\n",
    "[0.1226252158894646, 0.07743250127356088, 0.07779835935432654, 0.08468097618347545, 0.07636363636363637, 0.08695652173913043],\n",
    "\n",
    "[0.08981001727115717, 0.08006452708439464, 0.08004763164858428, 0.08174066451043811, 0.08, 0.08695652173913043]]\n",
    "\n",
    "\n",
    "prec=[[0.7515527950310559, 0.6890862944162437, 0.6891891891891891, 0.7118155619596542, 0.7228915662650602, 0.0],\n",
    "[0.762589928057554, 0.6813186813186813, 0.680373831775701, 0.7117117117117117, 0.7159090909090909, 0.0],\n",
    "\n",
    "[0.7435897435897436, 0.6788235294117647, 0.6781193490054249, 0.6981132075471698, 0.7127659574468085, 0.0],\n",
    "\n",
    "[0.7849462365591398, 0.6730987514188422, 0.6719298245614035, 0.7029702970297029, 0.7070707070707071, 0.0],\n",
    "\n",
    "[0.7464788732394366, 0.6710526315789473, 0.6683673469387755, 0.6875, 0.7047619047619048, 0.0],\n",
    "\n",
    "[0.8076923076923077, 0.6617179215270413, 0.6578512396694215, 0.697841726618705, 0.6727272727272727, 0.0]]\n",
    "\n",
    "\n",
    "\n",
    "rec=[[0.568075117370892, 0.4621276595744681, 0.4772727272727273, 0.4969818913480885, 0.42857142857142855, 0.0],\n",
    "\n",
    "[0.49765258215962443, 0.4748936170212766, 0.48663101604278075, 0.4768611670020121, 0.45, 0.0],\n",
    "\n",
    "[0.4084507042253521, 0.49106382978723406, 0.5013368983957219, 0.44668008048289737, 0.4785714285714286, 0.0],\n",
    "\n",
    "[0.3427230046948357, 0.5046808510638298, 0.5120320855614974, 0.42857142857142855, 0.5, 0.0],\n",
    "\n",
    "[0.24882629107981222, 0.5208510638297872, 0.5254010695187166, 0.3983903420523139, 0.5285714285714286, 0.0],\n",
    "\n",
    "[0.19718309859154928, 0.531063829787234, 0.5320855614973262, 0.3903420523138833, 0.5285714285714286, 0.0]]\n",
    "\n",
    "dp=[0.2345,0.17606,0.1337,0.088,0.04626,0.009]\n",
    "accu=[0.9183,0.9176,0.9168,0.9166,0.9157,0.9149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#P R R P R R        \n",
    "#0.4821  0.4774  0.4799  0.6459  0.3642\n",
    "#0.7058 0.4468 0.4438 0.6417  0.4071\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,3]\n",
    "r=[1,2,4]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "dp_list=[]\n",
    "     \n",
    "sizes=[579, 11778, 7558, 3401,1375,23]\n",
    "for i in range(6):\n",
    "    weight_prec=0\n",
    "    weight_p=0\n",
    "    weight_rec=0\n",
    "    weight_r=0\n",
    "    acc_list=[]\n",
    "    for j in range(5):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list) \n",
    "\n",
    "\n",
    "weight_prec=weighted_precision\n",
    "weight_rec=weighted_recall\n",
    "accu==accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the above results with DP variations\n",
    "#P R P R P R R \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#P R R P R R        \n",
    "#0.4821  0.4774  0.4799  0.6459  0.3642\n",
    "#0.7058 0.4468 0.4438 0.6417  0.4071\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,3]\n",
    "r=[1,2,4]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "dp_list=[]\n",
    "     \n",
    "sizes=[579, 11778, 7558, 3401,1375,23]\n",
    "for i in range(6):\n",
    "    weight_prec=0\n",
    "    weight_p=0\n",
    "    weight_rec=0\n",
    "    weight_r=0\n",
    "    acc_list=[]\n",
    "    for j in range(6):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list) \n",
    "\n",
    "\n",
    "weight_prec=weighted_precision\n",
    "weight_rec=weighted_recall\n",
    "accu==accu\n",
    "dp_a=dp_list\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "'''\n",
    "ax.plot(dp,y1,label='Weighted Precision',color='blue',marker='^',linestyle='-')  \n",
    "ax.plot(dp,y2,label='Weighted Recall',color='cyan',marker='^',linestyle='-')\n",
    "ax.plot(dp,y3,label=' Accuracy',color='red',marker='^',linestyle='-')\n",
    "'''\n",
    "ax.plot(dp_a,weight_prec,label='Weighted Precision',color='blue',marker='^',linestyle='--')  \n",
    "ax.plot(dp_a,weight_rec,label='Weighted Recall',color='cyan',marker='^',linestyle='--')\n",
    "ax.plot(dp_a,accu,label=' Accuracy',color='red',marker='^',linestyle='--')\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Demographic Disparity')\n",
    "ax.set_ylabel('Performance Metrics') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "fig.savefig('a2.png') \n",
    "\n",
    "print(dp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LP5 with beta weight mechanism on b_avg as .12, eps=.02\n",
    "accu_all,DP_all,acc_rate,alpha,prec,rec = main(sensitive, Y_test, Y_test_pred,e )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LP5 with beta weight mechanism on b_avg as .12\n",
    "\n",
    "acc_rate=[[0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216],\n",
    "[0.2659758203799655, 0.07760230939038885, 0.08084149245832231, 0.10585122022934432, 0.06909090909090909, 0.08695652173913043],\n",
    "[0.229706390328152, 0.08821531669213789, 0.09063244244509129, 0.10937959423698912, 0.08218181818181818, 0.08695652173913043],\n",
    "[0.19343696027633853, 0.09882832399388691, 0.10042339243186028, 0.11290796824463394, 0.09454545454545454, 0.13043478260869565],\n",
    "[0.15889464594127806, 0.10944133129563594, 0.11021434241862926, 0.11673037341958248, 0.10763636363636364, 0.13043478260869565],\n",
    "[0.13989637305699482, 0.12005433859738496, 0.12000529240539826, 0.12349309026756836, 0.12, 0.13043478260869565]]\n",
    "\n",
    "prec=[[0.7093023255813954, 0.6430379746835443, 0.6741154562383612, 0.6628242074927954, 0.4935064935064935, 0.0],\n",
    "[0.7419354838709677, 0.6265060240963856, 0.6546644844517185, 0.6638888888888889, 0.5052631578947369, 0.0],\n",
    "[0.7593984962406015, 0.5976900866217517, 0.6131386861313869, 0.6595174262734584, 0.5, 0.0],\n",
    "[0.7767857142857143, 0.5721649484536082, 0.5849802371541502, 0.6432291666666666, 0.47692307692307695, 0.0],\n",
    "[0.7717391304347826, 0.5554693560899923, 0.5630252100840336, 0.6372795969773299, 0.4391891891891892, 0.0],\n",
    "[0.7530864197530864, 0.5311173974540311, 0.5281146637265711, 0.6285714285714286, 0.41818181818181815, 0.0]]\n",
    "\n",
    "\n",
    "rec=[[0.5727699530516432, 0.4323404255319149, 0.4839572192513369, 0.46277665995975853, 0.2714285714285714, 0.0],\n",
    "[0.539906103286385, 0.4868085106382979, 0.5347593582887701, 0.48088531187122735, 0.34285714285714286, 0.0],\n",
    "[0.47417840375586856, 0.5285106382978724, 0.5614973262032086, 0.4949698189134809, 0.4, 0.0],\n",
    "[0.4084507042253521, 0.5668085106382978, 0.5935828877005348, 0.4969818913480885, 0.44285714285714284, 0.0],\n",
    "[0.3333333333333333, 0.6093617021276596, 0.6270053475935828, 0.5090543259557344, 0.4642857142857143, 0.0],\n",
    "[0.2863849765258216, 0.6391489361702127, 0.6403743315508021, 0.5311871227364185, 0.4928571428571429, 0.0]]\n",
    "\n",
    "accu=[0.9117, 0.9124, 0.9096, 0.9062, 0.9032, 0.8981]\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,3]\n",
    "r=[1,2,4]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "dp_list=[]\n",
    "     \n",
    "sizes=[579, 11778, 7558, 3401,1375]\n",
    "for i in range(6):\n",
    "    weight_prec=0\n",
    "    weight_p=0\n",
    "    weight_rec=0\n",
    "    weight_r=0\n",
    "    acc_list=[]\n",
    "    for j in range(5):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list) \n",
    "weight_prec=weighted_precision\n",
    "weight_rec=weighted_recall\n",
    "accu==accu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2,4,5 6 \n",
    "weight_prec_without_cv=[0.658889519139158, 0.6621044301782234, 0.664691759246754, 0.6485260922265532, 0.6413249521629499, 0.6511148808131968] \n",
    "weight_rec_without_cv=[0.456289490696973, 0.46114100162040683, 0.45772202644722854, 0.4552787915159377, 0.45040785895964397, 0.4430955718084552]\n",
    "weight_acc_without_cv=[0.914, 0.9128, 0.91, 0.9067, 0.9035, 0.9005] \n",
    "\n",
    "\n",
    "weight_prec_cv=[0.6695857226619661, 0.6752429035860305, 0.6740478633365177, 0.6626586242223019, 0.6568404185531754, 0.64668554412273] \n",
    "weight_rec_cv=[0.44049386706246846, 0.4947501540086412, 0.5320165655601464, 0.5683500881158362, 0.6061687703111742, 0.6298838269278305]\n",
    "weight_acc_cv=[]\n",
    "dp=[0.2410639032815199, 0.19688491128905639, 0.1475245721463338, 0.09889150573088398, 0.051258282304914415, 0.01989637305699482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####--->>>  result at delta1=[.95], gama=[.07], epsilon=[.04]\n",
    "import pulp as p \n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "alpha=[0 ,.2 ,.4 ,.6, .8 ,1]\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    "#acceptance_rate=np.transpose(acc_rate) \n",
    "a=[acc_rate[i][0]*100 for i in range(6)]  \n",
    "b=[acc_rate[i][1]*100 for i in range(6)]  \n",
    "c=[acc_rate[i][2]*100 for i in range(6)]  \n",
    "d=[acc_rate[i][3]*100 for i in range(6)]   \n",
    "e=[acc_rate[i][4]*100 for i in range(6)]  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  # 's_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo'\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(alpha,a,label='age>60 or age<25',color='red',linestyle='--') \n",
    "ax.plot(alpha,b,label='age>=25 and age<=60',color='brown',linestyle='--')  \n",
    "ax.plot(alpha,c,label='Married',color='blue',linestyle='--') \n",
    "ax.plot(alpha,d,label='Single',color='yellow',linestyle='--')\n",
    "ax.plot(alpha,e,label='Divorced',color='green',linestyle='--') \n",
    "\n",
    "\n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "fig.savefig('a1.png') \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "\n",
    "a=[prec[i][0] for i in range(6)]  \n",
    "\n",
    "c=[prec[i][3] for i in range(6)]  \n",
    "  \n",
    "x=[weight_prec[i] for i in range(6)] \n",
    "\n",
    "'''\n",
    "y1=savgol_filter(a, 6, 2)\n",
    "y2=savgol_filter(b, 6, 2)\n",
    "y3=savgol_filter(c, 6, 2)\n",
    "y4=savgol_filter(d, 6, 2)\n",
    "y5=savgol_filter(e, 6, 2)\n",
    "y6=savgol_filter(f, 6, 2)\n",
    "y7=savgol_filter(g, 6, 2)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.plot(alpha,a,label='age>60 or age<25(P)',color='red',linestyle='--') \n",
    " \n",
    "ax.plot(alpha,c,label='Married(P)',color='yellow',linestyle='--') \n",
    "\n",
    "ax.plot(alpha,x,label='Weighted Precision',color='black',marker='o',linestyle='-')\n",
    "\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel(' Precision ') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "fig.savefig('a2.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#P R P R P R R \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "\n",
    "\n",
    "b=[rec[i][1] for i in range(6)]  \n",
    " \n",
    "c=[rec[i][2] for i in range(6)]   \n",
    " \n",
    "e=[rec[i][4] for i in range(6)]\n",
    "y=[weight_rec[i] for i in range(6)] \n",
    "\n",
    "'''\n",
    "y1=savgol_filter(a, 6, 2)\n",
    "y2=savgol_filter(b, 6, 2)\n",
    "y3=savgol_filter(c, 6, 2)\n",
    "y4=savgol_filter(d, 6, 2)\n",
    "y5=savgol_filter(e, 6, 2)\n",
    "y6=savgol_filter(f, 6, 2)\n",
    "y7=savgol_filter(g, 6, 2)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "\n",
    "\n",
    "ax.plot(alpha,b,label='age>=25 and age<=60(R)',color='brown',linestyle='--')  \n",
    "ax.plot(alpha,c,label='Married(R)',color='blue',linestyle='--') \n",
    "ax.plot(alpha,e,label='Divorced(R)',color='green',linestyle='--') \n",
    "ax.plot(alpha,y,label='Weighted Recall',color='black',marker='o',linestyle='-')\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel('Recall') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "fig.savefig('a2.png') \n",
    "\n",
    "#P R P R P R R \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "\n",
    " \n",
    "c=[accu[i] for i in range(6)]  \n",
    "\n",
    "\n",
    "'''\n",
    "y1=savgol_filter(a, 6, 2)\n",
    "y2=savgol_filter(b, 6, 2)\n",
    "y3=savgol_filter(c, 6, 2)\n",
    "y4=savgol_filter(d, 6, 2)\n",
    "y5=savgol_filter(e, 6, 2)\n",
    "y6=savgol_filter(f, 6, 2)\n",
    "y7=savgol_filter(g, 6, 2)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "  \n",
    "ax.plot(alpha,c,label='',color='black',marker='o',linestyle='-') \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel('% Test Accuracy') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "#plt.show() \n",
    "plt.xlabel('Fairness parameter (alpha)')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('')\n",
    "plt.plot(alpha, c,color='black', linestyle='dashed', marker='.',\n",
    "     markerfacecolor='black', markersize=10)\n",
    "plt.savefig('a5.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LP5 with beta weight mechanism on b_avg as .12\n",
    "accu_all,DP_all,acc_rate,alpha,prec,rec = main(sensitive, Y_test, Y_test_pred,e )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look for fesible beta .02 with no weight even subgroup weights\n",
    "accu_all,DP_all,acc_rate,alpha,prec,rec = main(sensitive, Y_test, Y_test_pred,e )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look for fesible beta .02 with old same LP\n",
    "accu_all,DP_all,acc_rate,alpha,prec,rec = main(sensitive, Y_test, Y_test_pred,e )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' #check\n",
    "print(acc_rate)\n",
    "print(prec)\n",
    "print(rec)\n",
    "alpha=np.arange(0,1.2,.2)  \n",
    "print(accu)\n",
    "print(alpha)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for fesible beta .02 with old same LP\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred,e )\n",
    "\n",
    "#look for fesible beta .01 changed lp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "acc_rate=[[0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216],\n",
    "[0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043],\n",
    "[0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043],\n",
    "[0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043],\n",
    "[0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043],\n",
    "[0.08635578583765112, 0.07751740533197486, 0.07753373908441387, 0.07880035283740076, 0.07781818181818181, 0.08695652173913043]]\n",
    "\n",
    "prec=[[0.7151162790697675, 0.6506329113924051, 0.6759776536312849, 0.6628242074927954, 0.5714285714285714, 0.0],\n",
    "    [0.7449664429530202, 0.6461916461916462, 0.6709323583180987, 0.6737160120845922, 0.5662650602409639, 0.0],\n",
    "[0.7804878048780488, 0.6388557806912991, 0.6660682226211849, 0.6687898089171974, 0.5730337078651685, 0.0],\n",
    "[0.7731958762886598, 0.6338354577056778, 0.6537102473498233, 0.6666666666666666, 0.5684210526315789, 0.0],\n",
    "[0.7777777777777778, 0.6193693693693694, 0.6319444444444444, 0.6690391459074733, 0.5346534653465347, 0.0],\n",
    "[0.8035714285714286, 0.6107456140350878, 0.6125211505922166, 0.6865671641791045, 0.5233644859813084, 0.0]]\n",
    "\n",
    "rec=[[0.5774647887323944, 0.4374468085106383, 0.4852941176470588, 0.46277665995975853, 0.3142857142857143, 0.0],\n",
    "[0.5211267605633803, 0.44765957446808513, 0.49064171122994654, 0.448692152917505, 0.3357142857142857, 0.0],\n",
    "[0.4507042253521127, 0.45617021276595743, 0.4959893048128342, 0.4225352112676056, 0.36428571428571427, 0.0],\n",
    "[0.352112676056338, 0.465531914893617, 0.4946524064171123, 0.3983903420523139, 0.38571428571428573, 0.0],\n",
    "[0.26291079812206575, 0.46808510638297873, 0.48663101604278075, 0.3782696177062374, 0.38571428571428573,0.0],\n",
    "[0.2112676056338028, 0.47404255319148936, 0.4839572192513369, 0.3702213279678068, 0.4, 0.0]]\n",
    "\n",
    "\n",
    "accu=[.9129,.9128, .9121,.9106,.9080, 0.9067]\n",
    "#P R R P R R        \n",
    "#0.4821  0.4774  0.4799  0.6459  0.3642\n",
    "#0.7058 0.4468 0.4438 0.6417  0.4071\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,3]\n",
    "r=[1,2,4]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "dp_list=[]\n",
    "     \n",
    "sizes=[579, 11778, 7558, 3401,1375]\n",
    "for i in range(6):\n",
    "    weight_prec=0\n",
    "    weight_p=0\n",
    "    weight_rec=0\n",
    "    weight_r=0\n",
    "    acc_list=[]\n",
    "    for j in range(5):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_prec=weighted_precision\n",
    "weight_rec=weighted_recall\n",
    "accu==accu\n",
    "dp_a=[0.2410639032815199, 0.19697660543256398, 0.14770796043334905, 0.09843931543413409, 0.05089778615167216, 0.008838380505676258]\n",
    "#P R R P R\n",
    "#->1 4 5 6\n",
    "'''\n",
    "0.6537,0.6704\n",
    "0.4390,0.4467\n",
    "0.9104,0.9129\n",
    "\n",
    "0.6587,0.6821\n",
    "0.4500,0.4708\n",
    "0.9075,0.9106\n",
    "\n",
    "0.6528,0.6848\n",
    "0.4541,0.4693\n",
    "0.9062,0.908\n",
    "\n",
    "0.6477,0.7035\n",
    "0.4568,0.4727\n",
    "0.9044,0.9067\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "[0.6537399314783152, 0.6591800262507629, 0.6622803307440085, 0.6587194178787859, 0.6528199923584302, 0.6477083296726733] \n",
    "[0.4390498019862777, 0.44242498574518574, 0.44596605042551524, 0.45002671372726866, 0.4541023990251574, 0.4568930449817998] \n",
    "[0.9104, 0.9099, 0.909, 0.9075, 0.9062, 0.9044]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####--->>>  result at delta1=[.95], gama=[.07], epsilon=[.04]\n",
    "import pulp as p \n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "# delta1=[.8], gama=[.15], epsilon=[.01]\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "alpha=[0 ,.2 ,.4 ,.6, .8 ,1]\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    "#acceptance_rate=np.transpose(acc_rate) \n",
    "a=[acc_rate[i][0]*100 for i in range(6)]  \n",
    "b=[acc_rate[i][1]*100 for i in range(6)]  \n",
    "c=[acc_rate[i][2]*100 for i in range(6)]  \n",
    "d=[acc_rate[i][3]*100 for i in range(6)]   \n",
    "e=[acc_rate[i][4]*100 for i in range(6)]  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  # 's_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo'\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(alpha,a,label='age>60 or age<25',color='red',linestyle='--') \n",
    "ax.plot(alpha,b,label='age>=25 and age<=60',color='brown',linestyle='--')  \n",
    "ax.plot(alpha,c,label='Married',color='blue',linestyle='--') \n",
    "ax.plot(alpha,d,label='Single',color='yellow',linestyle='--')\n",
    "ax.plot(alpha,e,label='Divorced',color='green',linestyle='--') \n",
    "\n",
    "\n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "fig.savefig('a1.png') \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "\n",
    "a=[prec[i][0] for i in range(6)]  \n",
    "\n",
    "c=[prec[i][3] for i in range(6)]  \n",
    "  \n",
    "x=[weight_prec[i] for i in range(6)] \n",
    "\n",
    "'''\n",
    "y1=savgol_filter(a, 6, 2)\n",
    "y2=savgol_filter(b, 6, 2)\n",
    "y3=savgol_filter(c, 6, 2)\n",
    "y4=savgol_filter(d, 6, 2)\n",
    "y5=savgol_filter(e, 6, 2)\n",
    "y6=savgol_filter(f, 6, 2)\n",
    "y7=savgol_filter(g, 6, 2)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.plot(alpha,a,label='age>60 or age<25(P)',color='red',linestyle='--') \n",
    " \n",
    "ax.plot(alpha,c,label='Married(P)',color='yellow',linestyle='--') \n",
    "\n",
    "ax.plot(alpha,x,label='Weighted Precision',color='black',marker='o',linestyle='-')\n",
    "\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel(' Precision ') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "fig.savefig('a2.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#P R P R P R R \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "\n",
    "\n",
    "b=[rec[i][1] for i in range(6)]  \n",
    " \n",
    "c=[rec[i][2] for i in range(6)]   \n",
    " \n",
    "e=[rec[i][4] for i in range(6)]\n",
    "y=[weight_rec[i] for i in range(6)] \n",
    "\n",
    "'''\n",
    "y1=savgol_filter(a, 6, 2)\n",
    "y2=savgol_filter(b, 6, 2)\n",
    "y3=savgol_filter(c, 6, 2)\n",
    "y4=savgol_filter(d, 6, 2)\n",
    "y5=savgol_filter(e, 6, 2)\n",
    "y6=savgol_filter(f, 6, 2)\n",
    "y7=savgol_filter(g, 6, 2)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "\n",
    "\n",
    "ax.plot(alpha,b,label='age>=25 and age<=60(R)',color='brown',linestyle='--')  \n",
    "ax.plot(alpha,c,label='Married(R)',color='blue',linestyle='--') \n",
    "ax.plot(alpha,e,label='Divorced(R)',color='green',linestyle='--') \n",
    "ax.plot(alpha,y,label='Weighted Recall',color='black',marker='o',linestyle='-')\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel('Recall') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "fig.savefig('a2.png') \n",
    "\n",
    "#P R P R P R R \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "\n",
    " \n",
    "c=[accu[i] for i in range(6)]  \n",
    "\n",
    "\n",
    "'''\n",
    "y1=savgol_filter(a, 6, 2)\n",
    "y2=savgol_filter(b, 6, 2)\n",
    "y3=savgol_filter(c, 6, 2)\n",
    "y4=savgol_filter(d, 6, 2)\n",
    "y5=savgol_filter(e, 6, 2)\n",
    "y6=savgol_filter(f, 6, 2)\n",
    "y7=savgol_filter(g, 6, 2)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "  \n",
    "ax.plot(alpha,c,label='',color='black',marker='o',linestyle='-') \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Fairness parameter (alpha)')\n",
    "ax.set_ylabel('% Test Accuracy') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "#plt.show() \n",
    "plt.xlabel('Fairness parameter (alpha)')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('')\n",
    "plt.plot(alpha, c,color='black', linestyle='dashed', marker='.',\n",
    "     markerfacecolor='black', markersize=10)\n",
    "plt.savefig('a5.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "acc_rate=[[0.2970639032815199, 0.06707420614705382, 0.07105054247155332, 0.10202881505439576, 0.056, 0.043478260869565216],\n",
    "[0.25734024179620035, 0.06911190354898965, 0.0723736438211167, 0.09732431637753602, 0.06036363636363636, 0.08695652173913043],\n",
    "[0.21243523316062177, 0.07123450500933945, 0.07369674517068008, 0.09232578653337253, 0.06472727272727273, 0.08695652173913043],\n",
    "[0.16753022452504318, 0.07327220241127526, 0.07488753638528711, 0.08732725668920906, 0.06909090909090909, 0.08695652173913043],\n",
    "[0.12435233160621761, 0.07539480387162506, 0.07621063773485048, 0.0826227580123493, 0.07345454545454545, 0.08695652173913043],\n",
    "[0.08635578583765112, 0.07751740533197486, 0.07753373908441387, 0.07880035283740076, 0.07781818181818181, 0.08695652173913043]]\n",
    "\n",
    "prec=[[0.7151162790697675, 0.6506329113924051, 0.6759776536312849, 0.6628242074927954, 0.5714285714285714, 0.0],\n",
    "    [0.7449664429530202, 0.6461916461916462, 0.6709323583180987, 0.6737160120845922, 0.5662650602409639, 0.0],\n",
    "[0.7804878048780488, 0.6388557806912991, 0.6660682226211849, 0.6687898089171974, 0.5730337078651685, 0.0],\n",
    "[0.7731958762886598, 0.6338354577056778, 0.6537102473498233, 0.6666666666666666, 0.5684210526315789, 0.0],\n",
    "[0.7777777777777778, 0.6193693693693694, 0.6319444444444444, 0.6690391459074733, 0.5346534653465347, 0.0],\n",
    "[0.8035714285714286, 0.6107456140350878, 0.6125211505922166, 0.6865671641791045, 0.5233644859813084, 0.0]]\n",
    "\n",
    "rec=[[0.5774647887323944, 0.4374468085106383, 0.4852941176470588, 0.46277665995975853, 0.3142857142857143, 0.0],\n",
    "[0.5211267605633803, 0.44765957446808513, 0.49064171122994654, 0.448692152917505, 0.3357142857142857, 0.0],\n",
    "[0.4507042253521127, 0.45617021276595743, 0.4959893048128342, 0.4225352112676056, 0.36428571428571427, 0.0],\n",
    "[0.352112676056338, 0.465531914893617, 0.4946524064171123, 0.3983903420523139, 0.38571428571428573, 0.0],\n",
    "[0.26291079812206575, 0.46808510638297873, 0.48663101604278075, 0.3782696177062374, 0.38571428571428573,0.0],\n",
    "[0.2112676056338028, 0.47404255319148936, 0.4839572192513369, 0.3702213279678068, 0.4, 0.0]]\n",
    "\n",
    "\n",
    "accu=[.9129,.9128, .9121,.9106,.9080, 0.9067]\n",
    "#P R R P R R        \n",
    "#0.4821  0.4774  0.4799  0.6459  0.3642\n",
    "#0.7058 0.4468 0.4438 0.6417  0.4071\n",
    "\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,3]\n",
    "r=[1,2,4]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "dp_list=[]\n",
    "     \n",
    "sizes=[579, 11778, 7558, 3401,1375]\n",
    "for i in range(6):\n",
    "    weight_prec=0\n",
    "    weight_p=0\n",
    "    weight_rec=0\n",
    "    weight_r=0\n",
    "    acc_list=[]\n",
    "    for j in range(5):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list) \n",
    "\n",
    "\n",
    "weight_prec=weighted_precision\n",
    "weight_rec=weighted_recall\n",
    "accu==accu\n",
    "dp_a=[0.2410639032815199, 0.19697660543256398, 0.14770796043334905, 0.09843931543413409, 0.05089778615167216, 0.008838380505676258]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the above results with DP variations\n",
    "#P R P R P R R \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "'''\n",
    "ax.plot(dp,y1,label='Weighted Precision',color='blue',marker='^',linestyle='-')  \n",
    "ax.plot(dp,y2,label='Weighted Recall',color='cyan',marker='^',linestyle='-')\n",
    "ax.plot(dp,y3,label=' Accuracy',color='red',marker='^',linestyle='-')\n",
    "'''\n",
    "ax.plot(dp_a,weight_prec,label='Weighted Precision',color='blue',marker='^',linestyle='--')  \n",
    "ax.plot(dp_a,weight_rec,label='Weighted Recall',color='cyan',marker='^',linestyle='--')\n",
    "ax.plot(dp_a,accu,label=' Accuracy',color='red',marker='^',linestyle='--')\n",
    "\n",
    "   \n",
    "plt.title('')\n",
    "ax.set_xlabel('Demographic Disparity')\n",
    "ax.set_ylabel('Performance Metrics') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "fig.savefig('a2.png') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec=[[0.6521739130434783, 0.6539278131634819, 0.6887417218543046, 0.7279411764705882, 0.2909090909090909, 0.0],\n",
    "[0.7142857142857143, 0.6360544217687075, 0.6790450928381963, 0.6941176470588235, 0.29411764705882354, 0.0],\n",
    "[0.7352941176470589, 0.6260623229461756, 0.673289183222958, 0.6813725490196079, 0.2804878048780488, 0.0],\n",
    "[0.7608695652173914, 0.578556263269639, 0.6225165562913907, 0.6544117647058824, 0.23636363636363636, 0.0],\n",
    "[0.7790697674418605, 0.4535673839184598, 0.4651368049426302, 0.5941176470588235, 0.18446601941747573, 0.0],\n",
    "[0.7739130434782608, 0.3842887473460722, 0.3831899404367968, 0.5367647058823529, 0.1781818181818182, 0.25],\n",
    "[0.7283950617283951, 0.30087958750379135, 0.29820415879017015, 0.43067226890756305, 0.17662337662337663, 0.16666666666666666],\n",
    "[0.7167630057803468, 0.28474384375884515, 0.28054697838553155, 0.4117647058823529, 0.17475728155339806, 0.2857142857142857]\n",
    "]\n",
    "\n",
    "rec=[[0.07042253521126761, 0.2621276595744681, 0.27807486631016043, 0.19919517102615694, 0.11428571428571428, 0.0],\n",
    "[0.09389671361502347, 0.31829787234042556, 0.3422459893048128, 0.23742454728370221, 0.14285714285714285, 0.0],\n",
    "[0.11737089201877934, 0.37617021276595747, 0.4077540106951872, 0.2796780684104628, 0.16428571428571428, 0.0],\n",
    "[0.1643192488262911, 0.46382978723404256, 0.5026737967914439, 0.358148893360161, 0.18571428571428572, 0.0],\n",
    "[0.3145539906103286, 0.6817021276595745, 0.7045454545454546, 0.6096579476861167, 0.2714285714285714, 0.0],\n",
    "[0.41784037558685444, 0.7702127659574468, 0.7740641711229946, 0.7344064386317908, 0.35, 0.3333333333333333],\n",
    "[0.5539906103286385, 0.8442553191489361, 0.8435828877005348, 0.8249496981891348, 0.4857142857142857, 0.3333333333333333],\n",
    "       [0.5821596244131455, 0.8561702127659574, 0.8502673796791443, 0.8450704225352113, 0.5142857142857142, 0.6666666666666666]\n",
    "]\n",
    "\n",
    "accu=[0.8999, 0.9015 , 0.9033 ,0.9015 ,0.8782 ,0.8486, 0.7874, 0.7706]\n",
    "\n",
    "beta=[.04,.05,.06,.08,.15,.20,.28,.3]\n",
    "\n",
    "beta_p=[]\n",
    "beta_r=[]\n",
    "beta_check=[0.0434,.0567,.0692,.0717,.1020,.29]\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#P R P R P R R \n",
    "#0.7251,0.8101 0.5470,0.7329 0.6311,0.7389 0.5308,0.6172 0.6764,0.4776  0.4666,0.5333  0.2666,0.7333\n",
    "#      \n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "#p=[]\n",
    "#r=[0,2,4,1,3,5,6]\n",
    "\n",
    "dp_list=[]\n",
    "sizes=[579, 11778, 7558, 3401,1375,23]\n",
    "for i in range(8):\n",
    "    weight_prec=0\n",
    "    weight_p=0\n",
    "    weight_rec=0\n",
    "    weight_r=0\n",
    "    cnt1=0\n",
    "    cnt2=0\n",
    "    for j in range(6):\n",
    "        #print(j)\n",
    "              \n",
    "        \n",
    "        if beta[i] <=beta_check[j]:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            cnt1=1\n",
    "        else:  \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "            cnt2=1\n",
    "    if cnt1==1:\n",
    "        wp=weight_prec/weight_p\n",
    "        weighted_precision.append(wp)\n",
    "        beta_p.append(beta[i])\n",
    "\n",
    "    if cnt2==1: \n",
    "        wr=weight_rec/weight_r\n",
    "        weighted_recall.append(wr) \n",
    "        beta_r.append(beta[i])\n",
    "            \n",
    "   \n",
    "    \n",
    "    \n",
    "len1=(len(weighted_precision)) \n",
    "len2=(len(weighted_recall)) \n",
    "    \n",
    "print(weighted_precision, weighted_recall,beta_p,beta_r,len1,len2)\n",
    "'''\n",
    "[0.9520125938773091, 0.9403591343418822, 0.8608764055619338],0.8561212064210523, 0.8128034718440105, 0.782912341254576, 0.7358009995069338\n",
    "0.4610404591572201, 0.5551300667433751, 0.5983458776930215, 0.6580824258162613,0.6476895465902177, 0.7070185074558867, 0.754950250161771\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "np.set_printoptions(precision=4)  # For compact display.\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "\n",
    "'''\n",
    "y1=savgol_filter(a, 6, 2)\n",
    "y2=savgol_filter(b, 6, 2)\n",
    "y3=savgol_filter(c, 6, 2)\n",
    "y4=savgol_filter(d, 6, 2)\n",
    "y5=savgol_filter(e, 6, 2)\n",
    "y6=savgol_filter(f, 6, 2)\n",
    "y7=savgol_filter(g, 6, 2)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "weighted_precision=[0.6539131000260164, 0.6376124994247303, 0.6305525951057798, 0.23247496423462088, 0.0, 0.25, 0.16666666666666666] \n",
    "weighted_recall=[0.09389671361502347, 0.36404390324806346, 0.4535684088857701, 0.6473139982741551, 0.7347956274774579, 0.8146170768278111, 0.8272203909373664]\n",
    "beta1=[0.04, 0.05, 0.06, 0.08, 0.15, 0.2, 0.28]\n",
    "beta2=[0.05, 0.06, 0.08, 0.15, 0.2, 0.28, 0.3]\n",
    "accu=[0.8999, 0.9015 , 0.9033 ,0.9015 ,0.8782 ,0.8486, 0.7874, 0.7706]\n",
    "\n",
    "'''\n",
    "weighted_precision=[0.9520125938773091, 0.9403591343418822, 0.8608764055619338,0.8561212064210523, 0.8128034718440105, 0.782912341254576, 0.7358009995069338]\n",
    "weighted_recall=[0.4610404591572201, 0.5551300667433751, 0.5983458776930215, 0.6580824258162613,0.6476895465902177, 0.7070185074558867, 0.754950250161771]\n",
    "beta1=[.02,.025,.05,.1,.14,.16,.2]\n",
    "beta2=[.1,.14,.16,.2,.25,.3,.35]\n",
    "\n",
    "accu=[ 0.7774,0.7813,0.7954,0.8157,0.82442,0.8245,0.8216,0.8146,0.7954,0.7699]\n",
    "'''\n",
    "ax.plot(beta1,weighted_precision,label='Weighted Precision',color='blue',marker='^',linestyle='--')  \n",
    "ax.plot(beta2,weighted_recall,label='Weighted Recall',color='cyan',marker='^',linestyle='--')\n",
    "ax.plot(beta,accu,label=' Accuracy',color='red',marker='^',linestyle='--')\n",
    "#ax.vlines(y=[.1992], ymin=[0], ymax=[1], colors='purple', linestyles='--', lw=2, label='PRedict avg. acc.')\n",
    "#plt.axvline(.1992, color='green', linestyle='--')\n",
    "#plt.axvline(.10, color='orange', linestyle='--')\n",
    "#plt.axvline(.20, color='orange', linestyle='--')\n",
    "plt.axvline(0.0434, color='orange', linestyle='--')\n",
    "plt.axvline(0.0567, color='orange', linestyle='--')\n",
    "plt.axvline(0.0692, color='orange', linestyle='--')\n",
    "plt.axvline(0.0717, color='orange', linestyle='--')\n",
    "plt.axvline(0.1020, color='orange', linestyle='--')\n",
    "plt.axvline(0.2689, color='orange', linestyle='--')\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "plt.title('')\n",
    "ax.set_xlabel('Acceptance Rate')\n",
    "ax.set_ylabel('Performance Metrics') \n",
    "# ax.set_ylabel('% in +ve class (Acceptance Rate)') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n",
    "fig.savefig('a2.png') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
