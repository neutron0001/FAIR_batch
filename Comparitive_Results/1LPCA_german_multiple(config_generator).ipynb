{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest For German\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def german_rf(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10,shuffle=True)     #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "#     from sklearn.svm import SVC\n",
    "#     svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=99, max_depth=None, min_samples_split=15, random_state=0)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    rf.fit(X_train, Y_train)\n",
    "    print('The accuracy of the RF classifier on training data is {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "    print('The accuracy of the RF classifier on test data is {:.2f}'.format(rf.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=rf.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=rf.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=rf.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(datax, y_test, y_test_pred,e): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"Random Forest---------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "  \n",
    " \n",
    "    \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    \n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "#COMMENT   : \"ar\" #############use this predicted RandomForet accptance rate(config) hardcoded or\n",
    "#can pass it through LPCA as lpca() \n",
    "#above ar: Random forest acceptance rate is use as beta_initial/beta (named as beata_initial in paper)\n",
    "######################################RF acceptance rate as beta_initial #############   \n",
    "    beta_initial=ar\n",
    "\n",
    "########################################################################################      \n",
    "    \n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"Random Forest accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(\"prec--reca--accur\")\n",
    "    print(prec,reca,accur)\n",
    "    ########################COMMENTS\n",
    "######################SET input parameters of users choice beta_ converge,  \n",
    "\n",
    "    \n",
    "#(beta_converge, alpha and epsilon are the parameters of LPCA ) \n",
    "# alpha=1 use initial predicted(beta configs) by classifier (RF), at alpha=0 converges to Least DDP config at beta_converge\n",
    "#Example for beta_converge =[.75]\n",
    "\n",
    "\n",
    "    epsilon=[.005,.01]\n",
    "    #beta_converge = [0.4539,0.5119]\n",
    "    beta_converge = [.75]\n",
    "    alpha = [1,.8,.6,.4,.2,0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    fi= np.zeros(n,dtype=int) \n",
    "\n",
    "    t=0\n",
    "        \n",
    "    #\n",
    "    #gamma=[0.8795811518324608, 0.7614678899082569, 0.8571428571428571, 0.7454545454545455]\n",
    "#COMMENT\n",
    "    #beta_initial(passed in min_sum_lpca()) \n",
    "    #mentioned in min_sum_lpca():function cell below    \n",
    "    #beta_initial = [0.8795811518324608, 0.7614678899082569, 0.8571428571428571, 0.7454545454545455]\n",
    "\n",
    "    for eps in epsilon:\n",
    "        for beta_avg in beta_converge:\n",
    "            print(\"----------------This is for covergence at beta = \",beta_avg, \" ----------------\")\n",
    "            for a in alpha:\n",
    "               \n",
    "            ######COMMENT min_sum_lpca()\n",
    "#beta_initial passed in min_sum_lpca() with name beta_initial i.e acc_rate of RF can be paased dynamically\n",
    "            ##parameters\n",
    "                  #data: sensitive sub groups in adult it is 7 dimensional\n",
    "                  #beta_avg (beta^): convergence point from beta_initial(at alpha=1)\n",
    "                  #alpha=0 for minimum DDP achievement\n",
    "                    #eps: to contain config within eps(eps=.005 means achieving DDP<2*eps means <.01 DDP )      \n",
    "\n",
    "                u1,u2 = min_sum_lpca(data,beta_initial,eps,e,beta_avg,a)\n",
    "                #######################Disp_impact#######################  \n",
    "                print(\"alpha, beta_avg\",a,beta_avg)\n",
    "                accu_all=[]\n",
    "                DP_all=[]\n",
    "                precision_all=[]\n",
    "                recall_all=[]\n",
    "                ar_all=[]\n",
    "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "                count=0\n",
    "                print(\"<------epsilon-\",eps,\"-------------------------------->\")\n",
    "                t=t+1\n",
    "                print(\"iteration t\",t)\n",
    "       \n",
    "\n",
    "                for i in range(n):\n",
    "                     fi[i] = u1[i]\n",
    "\n",
    "\n",
    "                for j in range(s):\n",
    "                    print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "                    TP=0\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TN=0\n",
    "                    precision=0\n",
    "                    recall=0\n",
    "                    for i in range(n):\n",
    "                         if data[j][i]== 1 :                        \n",
    "                            if fi[i]==1 and r[i]==1:\n",
    "                                TP=TP+1\n",
    "                            if fi[i]==1 and r[i]==-1:\n",
    "                                FP=FP+1 \n",
    "                            if fi[i]==-1 and r[i]==1:\n",
    "                                FN=FN+1\n",
    "                            if fi[i]==-1 and r[i]==-1:\n",
    "                                TN=TN+1    \n",
    "                    if TP+FP !=0:\n",
    "                        precision=float(TP/(TP+FP))\n",
    "                    #print(\"precision\",precision)\n",
    "                    if TP+FN !=0:    \n",
    "                        recall=float(TP/(TP+FN))\n",
    "                   # print(\"recall\",recall)\n",
    "\n",
    "                    precision_all.append(precision)\n",
    "                    recall_all.append(recall)\n",
    "                    #print(\"TP,FP,TN,FN\")\n",
    "                    #print(TP,FP,TN,FN)\n",
    "\n",
    "                    a=0\n",
    "                    b=0\n",
    "                    acc1=0\n",
    "                    acc2=0\n",
    "                    for i in range(n):\n",
    "                            if data[j][i]== 1 :\n",
    "                                a=a+1\n",
    "                                if fi[i]==1:\n",
    "                                     acc1=acc1+1 \n",
    "\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                    a1=float(acc1/a)\n",
    "\n",
    "\n",
    "\n",
    "        #                         print(a)\n",
    "        #                         print(acc1)\n",
    "        #                         print(a1)\n",
    "                    ar_all.append(a1)\n",
    "\n",
    "                count = count+1\n",
    "                maxi=max(ar_all)\n",
    "                mini= min(ar_all)\n",
    "                DP=float(maxi-mini)\n",
    "                print(\"individual acceptance rates\")\n",
    "                print(ar_all)\n",
    "                print(\"individual precision\")\n",
    "                print(precision_all)\n",
    "                print(\"individual recall\")\n",
    "                print(recall_all)\n",
    "                print(\"DP all\")\n",
    "                print(DP)\n",
    "                f_acc=0\n",
    "                for i in range(n):\n",
    "                     if fi[i] == r[i]:\n",
    "                            f_acc=f_acc+1\n",
    "                f_acc_l=float((f_acc*100)/n) \n",
    "\n",
    "        #######################################################################33   \n",
    "\n",
    "        #                         print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                TP=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TN=0\n",
    "                precision=0\n",
    "                recall=0\n",
    "                accu=0\n",
    "                for i in range(n):\n",
    "                        if fi[i]==1 and r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        if fi[i]==1 and r[i]==-1:\n",
    "                            FP=FP+1 \n",
    "                        if fi[i]==-1 and r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        if fi[i]==-1 and r[i]==-1:\n",
    "                            TN=TN+1    \n",
    "\n",
    "                if TP+FP!=0:\n",
    "                    precision=float(TP/(TP+FP))\n",
    "                print(\"precision all\",precision)\n",
    "                if TP+FN!=0:\n",
    "                    recall=float(TP/(TP+FN))\n",
    "\n",
    "\n",
    "                print(\"recall all\",recall)\n",
    "                accu=float((TP+TN)/(TP+FN+TN+FP))\n",
    "\n",
    "\n",
    "                print(\"accuracy all\",accu)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"TP,FP,TN,FN\")\n",
    "                print(TP,FP,TN,FN)\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "          \n",
    "\n",
    "    print(\"<--------------------------------------->\")\n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################LPCA######CODE######to corverge in given beta_avg setting###########by varying alpha from 1 to 0\n",
    "\n",
    "#data1 is sensitive group in binary matrix sets \n",
    "import time\n",
    "import pulp as p \n",
    "def min_sum_lpca(data1,beta,eps,e,beta_avg,alpha):\n",
    "    import pulp as p \n",
    "    import math\n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    \n",
    "    ################ sorted result\n",
    "    h1=[]\n",
    "    h2=[]\n",
    "    h3=[]\n",
    "    h4=[]\n",
    "    key1=[]\n",
    "    key2=[]\n",
    "    key3=[]\n",
    "    key4=[]\n",
    "    cost=np.zeros(n,dtype=int)\n",
    "    data2=np.zeros((m,n),dtype=int)\n",
    "    for i in range(n):\n",
    "        if data1[0][i]==1:            \n",
    "\n",
    "            h1.append(e[i][1])\n",
    "            key1.append(i)\n",
    "        elif data1[1][i]==1:\n",
    "            h2.append(e[i][1])\n",
    "            key2.append(i)\n",
    "            \n",
    "        if data1[2][i]==1:\n",
    "            h3.append(e[i][1])\n",
    "            key3.append(i)\n",
    "            \n",
    "        elif data1[3][i]==1:\n",
    "            h4.append(e[i][1])\n",
    "            key4.append(i)    \n",
    "\n",
    "\n",
    "    for i in range(1,len(h1)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h1[j-1]<h1[j]:\n",
    "                index=j\n",
    "                var=h1[j]\n",
    "                h1[j]=h1[j-1]\n",
    "                h1[j-1]=var\n",
    "\n",
    "                var2=key1[j]\n",
    "                key1[j]=key1[j-1]\n",
    "                key1[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "            \n",
    "\n",
    "    for i in range(1,len(h2)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h2[j-1]<h2[j]:\n",
    "                index=j\n",
    "                var=h2[j]\n",
    "                h2[j]=h2[j-1]\n",
    "                h2[j-1]=var\n",
    "\n",
    "                var2=key2[j]\n",
    "                key2[j]=key2[j-1]\n",
    "                key2[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h3)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h3[j]:\n",
    "                index=j\n",
    "                var=h3[j]\n",
    "                h3[j]=h3[j-1]\n",
    "                h3[j-1]=var\n",
    "\n",
    "                var2=key3[j]\n",
    "                key3[j]=key3[j-1]\n",
    "                key3[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "\n",
    "    for i in range(1,len(h4)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h4[j-1]<h4[j]:\n",
    "                index=j\n",
    "                var=h4[j]\n",
    "                h4[j]=h4[j-1]\n",
    "                h4[j-1]=var\n",
    "\n",
    "                var2=key4[j]\n",
    "                key4[j]=key4[j-1]\n",
    "                key4[j-1]=var2\n",
    "            else:\n",
    "                break            \n",
    "    \n",
    "    \n",
    "    alpha2=[1,1,1,1]\n",
    "    \n",
    " #####alpha2 is just another weight influencing parameter for now its neutral with [\"ones\"] vector    \n",
    "    for j in range(len(key1)):    \n",
    "        data2[0][key1[j]]=(j+1)*alpha2[0]\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)*((beta[0]*len(key1))*(beta[1]*len(key2)))*alpha2[1]\n",
    "        \n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)*alpha2[2]\n",
    "                      \n",
    "        \n",
    "    for j in range(len(key4)):\n",
    "        data2[3][key4[j]]=(j+1)*((beta[2]*len(key3))*(beta[3]*len(key4)))*alpha2[3]  \n",
    "      \n",
    "    ########################################################################    \n",
    "#sum up the weighted subgroup rank in cost \n",
    "    for j in range(n):\n",
    "        summ=0\n",
    "        for i in range(m):\n",
    "       \n",
    "            summ=summ+data2[i][j] \n",
    "        cost[j]=summ\n",
    "\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    \n",
    "###############################Optimization fuction for LPCA###################\n",
    "# beta_avg(convergence point to achieve least DP at alpha=0   \n",
    "# beta_actual is beta_initial (acceptance rate) config obtaind for each group from random forest prediction)   \n",
    "\n",
    "\n",
    "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
    "    Y=np.zeros(m,dtype=p.LpVariable)\n",
    "    \n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    \n",
    "#sum up the subgroup ranks in cost   \n",
    "    max_size=0\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1 \n",
    "        if count>max_size:\n",
    "            max_size=count\n",
    "        sizes[i]=count\n",
    "    print(sizes)        \n",
    "    \n",
    "    \n",
    "    \n",
    "    beta_initial=beta\n",
    "    #beta_initial = gamma\n",
    "    \n",
    "    select_sizes=np.zeros(m,dtype=int)\n",
    "   \n",
    "    size_final=np.zeros(m,dtype=int)\n",
    "\n",
    "    for i in range(m):\n",
    "        var1 = str(n+100+i)\n",
    "        Y[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Continuous')\n",
    "    \n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "   \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
    "\n",
    "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)])\n",
    "    \n",
    "\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= (Y[i]-eps)*sizes[i]\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= (Y[i]+eps)*sizes[i]\n",
    "    \n",
    "    '''\n",
    "# for minimum ddp at alpa=0 setup (like paper) change (1- alpha) to (alpha) & (alpha) to (1-alpha)    \n",
    "    for i in range(m):\n",
    "            if beta_initial[i] >= beta_avg:\n",
    "\n",
    "                Lp_prob += Y[i] >= (1-alpha)*beta_initial[i] +alpha*beta_avg\n",
    "                Lp_prob += Y[i] <= (1-alpha)*beta_initial[i] +alpha*beta_avg\n",
    "               \n",
    "            else:\n",
    "                Lp_prob += Y[i] >= (1-alpha)*beta_initial[i] + alpha*beta_avg\n",
    "                Lp_prob += Y[i] <= beta_avg   \n",
    "    '''      \n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "            if beta_initial[i] >= beta_avg:\n",
    "\n",
    "                Lp_prob += Y[i] >= (alpha)*beta_initial[i] +(1-alpha)*beta_avg\n",
    "                Lp_prob += Y[i] <= (alpha)*beta_initial[i] +(1-alpha)*beta_avg\n",
    "               \n",
    "            else:\n",
    "                Lp_prob += Y[i] >= (alpha)*beta_initial[i] + (1-alpha)*beta_avg\n",
    "                Lp_prob += Y[i] <= beta_avg               \n",
    "   \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"objective is:\")        \n",
    "    #print(p.value(Lp_prob.objective))\n",
    "    print(\"discripency is:\") \n",
    "    print(p.value(X[n]))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "from sklearn import preprocessing\n",
    "# Add column names to data set\n",
    "\n",
    "data= pd.read_csv('data/german.csv' , skipinitialspace=True)\n",
    "print(data.head())\n",
    "print(data.shape[0],data.shape[1])\n",
    "\n",
    "#sensitive columns name '12'='age','8'='gender/personal_status'  '19'- foreign workers 20'=1(good)/2(bad))\n",
    "\n",
    "# print(sens)\n",
    "r=data[['20']]\n",
    "# print(r)\n",
    "p=data.shape[0]\n",
    "for i in range(0,p):  \n",
    "    if data.loc[i,\"12\"]>25 :\n",
    "               data.loc[i,\"12\"] = 1 \n",
    "    else :\n",
    "               data.loc[i,\"12\"] = 2\n",
    "    if r.loc[i,'20'] == 1 :\n",
    "               r.loc[i,\"20\"] = 1 \n",
    "    else: \n",
    "               r.loc[i,\"20\"] = 0  \n",
    "            \n",
    "print(data['20'].value_counts())            \n",
    "\n",
    "print(data['8'].value_counts())\n",
    "print(data['12'].value_counts())\n",
    "print(data['19'].value_counts())\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "'''\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "num_col = dat.dtypes[dat.dtypes != 'object'].index\n",
    "features_log_minmax_transform = pd.DataFrame(data = dat)\n",
    "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
    "\n",
    "\n",
    "display(features_log_minmax_transform.head())\n",
    "'''\n",
    "\n",
    "# sens=DATA[['sex','race']]\n",
    "#Data_c = pd.get_dummies(features_log_minmax_transform, columns=['sex','race','workclass','education','marital-status','occupation','relationship','native-country'], prefix =['s','r','work','edu','ms','occ','rls','nc'])\n",
    "m=data.shape[1]\n",
    "data_c1=data.iloc[:,0:m-1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_c2 = min_max_scaler.fit_transform(data_c1)\n",
    "data_c = pd.DataFrame(data_c2,columns=data_c1.columns)\n",
    "print(data_c)\n",
    "\n",
    "\n",
    "\n",
    "X_test,Y_test_pred,Y_test,e = german_rf(data_c , r)\n",
    "#print(X_test.iloc[:,:])\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(X_test)\n",
    "# print(Y_test_pred)\n",
    "# print(Y_test)\n",
    "sens=X_test[['8', '12' ]]\n",
    "# print(sens)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "     \n",
    "# for i in range(0,p):  \n",
    "#     if r.loc[i,'y'] == 1 :\n",
    "#                r.loc[i,\"y\"] = 1 \n",
    "#     else: \n",
    "#                r.loc[i,\"y\"] = 0 \n",
    "print(sens['8'].value_counts())            \n",
    "print(sens['12'].value_counts())\n",
    "#print(sens['19'].value_counts())\n",
    "sens1=pd.get_dummies(sens, columns=['8','12'], prefix =['8','12'])\n",
    "sensitive=sens1.T\n",
    "print(sensitive) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BETA=.75\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitive, Y_test, Y_test_pred ,e)\n",
    "\n",
    "\n",
    "# Observe group wise acc_rate,precision, recall, DP\n",
    "#eps=.005 ensures DDP<.01\n",
    "#see the the convergence at alpha =0\n",
    "#SEE Optimal group wise acceptance rate/config (individual beta) with varying alpha\n",
    "\n",
    "#observe valid configurations only\n",
    "\n",
    "#optimal before iterations tells the valid configuration on parameters.\n",
    "#undefined ,means invalid configuration on given parameters\n",
    "       #if undefined increase eps from .005 to .01 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta convegence at.75 LPCA with weights\n",
    "acc_rate=[[0.8795811518324608, 0.7614678899082569, 0.8571428571428571, 0.7454545454545455],\n",
    "[0.8534031413612565, 0.7614678899082569, 0.8367346938775511, 0.7454545454545455],\n",
    "[0.8272251308900523, 0.7522935779816514, 0.8122448979591836, 0.7454545454545455],\n",
    "[0.8010471204188482, 0.7522935779816514, 0.7918367346938775, 0.7454545454545455],\n",
    "[0.774869109947644, 0.7522935779816514, 0.7714285714285715, 0.7454545454545455],\n",
    "[0.7486910994764397, 0.7522935779816514, 0.7510204081632653, 0.7454545454545455]]\n",
    "\n",
    "\n",
    "prec=[\n",
    "[0.8095238095238095, 0.7108433734939759, 0.8, 0.6585365853658537],\n",
    "[0.8159509202453987, 0.7108433734939759, 0.8048780487804879, 0.6585365853658537],\n",
    "[0.810126582278481, 0.7073170731707317, 0.7989949748743719, 0.6585365853658537],\n",
    "[0.8169934640522876, 0.7073170731707317, 0.8041237113402062, 0.6585365853658537],\n",
    "[0.831081081081081, 0.7073170731707317, 0.8148148148148148, 0.6585365853658537],\n",
    "[0.8321678321678322, 0.7073170731707317, 0.8152173913043478, 0.6585365853658537]]\n",
    "rec=[\n",
    "[0.9714285714285714, 0.9365079365079365, 0.9710982658959537, 0.9],\n",
    "[0.95, 0.9365079365079365, 0.953757225433526, 0.9],\n",
    "[0.9142857142857143, 0.9206349206349206, 0.9190751445086706, 0.9],\n",
    "[0.8928571428571429, 0.9206349206349206, 0.9017341040462428, 0.9],\n",
    "[0.8785714285714286, 0.9206349206349206, 0.8901734104046243, 0.9],\n",
    "[0.85, 0.9206349206349206, 0.8670520231213873, 0.9]]\n",
    "dp=[0.1341,0.1079,0.0817,0.0555,0.02941,0.0068]\n",
    "\n",
    "accu=[0.7866, 0.7833,0.76333,0.76,0.7633,0.7533]\n",
    "\n",
    "\n",
    "#0.5756,0.6218  0.6674,0.6788  0.6188,0.6451  0.6016,0.6097\n",
    "#R P P R\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,2]\n",
    "r=[1,3]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "sizes=[181,109,245,55]\n",
    "dp_list=[]\n",
    "\n",
    "for i in range(6):\n",
    "    weight_prec=0\n",
    "    weight_rec=0\n",
    "    weight_p=0\n",
    "    weight_r=0\n",
    "    acc_list=[]\n",
    "    for j in range(4):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LPCA Result\n",
    "import pulp as p \n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "alpha=[0 ,.2 ,.4 ,.6, .8 ,1]\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    " \n",
    "x=[weighted_precision[i] for i in range(6)]\n",
    "y=[weighted_recall[i] for i in range(6)]  \n",
    "z=[accu[i] for i in range(6)]   \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(dp_list,x,label='Weighted Precision',color='blue',marker='^',linestyle='--')\n",
    "ax.plot(dp_list,y,label='Weighted Recall',color='cyan',marker='^',linestyle='--')\n",
    "ax.plot(dp_list,z,label='Accuracy',color='red',marker='^',linestyle='--') \n",
    " \n",
    "\n",
    "\n",
    "plt.title('')\n",
    "ax.set_xlabel('Demographic Disparity')\n",
    "ax.set_ylabel('Performance Metrics') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta convegence at.75 LPCA without weights\n",
    "acc_rate=[[0.8795811518324608, 0.7614678899082569, 0.8571428571428571, 0.7454545454545455],\n",
    "[0.8534031413612565, 0.7614678899082569, 0.8367346938775511, 0.7454545454545455],\n",
    "[0.8272251308900523, 0.7522935779816514, 0.8122448979591836, 0.7454545454545455],\n",
    "[0.8010471204188482, 0.7522935779816514, 0.7918367346938775, 0.7454545454545455],\n",
    "[0.774869109947644, 0.7522935779816514, 0.7714285714285715, 0.7454545454545455],\n",
    "[0.7486910994764397, 0.7522935779816514, 0.7510204081632653, 0.7454545454545455]]\n",
    "\n",
    "\n",
    "prec=[[0.8095238095238095, 0.7108433734939759, 0.8, 0.6585365853658537],\n",
    "[0.8159509202453987, 0.7108433734939759, 0.8048780487804879, 0.6585365853658537],\n",
    "[0.810126582278481, 0.7073170731707317, 0.7989949748743719, 0.6585365853658537],\n",
    "[0.8235294117647058, 0.7195121951219512, 0.8092783505154639, 0.6829268292682927],\n",
    "[0.831081081081081, 0.7195121951219512, 0.8201058201058201, 0.6585365853658537],\n",
    "[0.8391608391608392, 0.7195121951219512, 0.8315217391304348, 0.6341463414634146]]\n",
    "\n",
    "rec=[[0.9714285714285714, 0.9365079365079365, 0.9710982658959537, 0.9],\n",
    "[0.95, 0.9365079365079365, 0.953757225433526, 0.9],\n",
    "[0.9142857142857143, 0.9206349206349206, 0.9190751445086706, 0.9],\n",
    "[0.9, 0.9365079365079365, 0.9075144508670521, 0.9333333333333333],\n",
    "[0.8785714285714286, 0.9365079365079365, 0.8959537572254336, 0.9],\n",
    "[0.8571428571428571, 0.9365079365079365, 0.884393063583815, 0.8666666666666667]]\n",
    "\n",
    "dp=[0.1341,0.1079,0.0817,0.0555,0.0294,0.0068]\n",
    "\n",
    "accu=[0.7866,0.7833,0.7633,0.7733,0.77,0.7666666666666667]\n",
    "#0.5756,0.6218  0.6674,0.6788  0.6188,0.6451  0.6016,0.6097\n",
    "#R P P R\n",
    "weighted_precision=[]\n",
    "weighted_recall=[]\n",
    "p=[0,2]\n",
    "r=[1,3]\n",
    "print(np.transpose(acc_rate))\n",
    "weight_prec=0\n",
    "weight_p=0\n",
    "weight_rec=0\n",
    "weight_r=0\n",
    "sizes=[181,109,245,55]\n",
    "dp_list=[]\n",
    "\n",
    "for i in range(6):\n",
    "    weight_prec=0\n",
    "    weight_rec=0\n",
    "    weight_p=0\n",
    "    weight_r=0\n",
    "    acc_list=[]\n",
    "    for j in range(4):\n",
    "        #print(j)\n",
    "        if j in p:\n",
    "            weight_prec=weight_prec+sizes[j]*prec[i][j]\n",
    "            weight_p=weight_p+sizes[j]\n",
    "            #print(j)\n",
    "        if j in r:    \n",
    "            weight_rec=weight_rec+sizes[j]*rec[i][j]\n",
    "            weight_r=weight_r+sizes[j]\n",
    "        #print(acc_rate[i][j])    \n",
    "        acc_list.append(acc_rate[i][j])\n",
    "    #print(acc_list)\n",
    "    dp=max(acc_list)-min(acc_list)   \n",
    "    dp_list.append(dp)     \n",
    "    wp=weight_prec/weight_p\n",
    "    wr=weight_rec/weight_r\n",
    "    weighted_precision.append(wp)\n",
    "    weighted_recall.append(wr)\n",
    "print(weighted_precision, weighted_recall,accu,dp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LPCA Result\n",
    "import pulp as p \n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "alpha=[0 ,.2 ,.4 ,.6, .8 ,1]\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    " \n",
    "x=[weighted_precision[i] for i in range(6)]\n",
    "y=[weighted_recall[i] for i in range(6)]  \n",
    "z=[accu[i] for i in range(6)]   \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(dp_list,x,label='Weighted Precision',color='blue',marker='^',linestyle='--')\n",
    "ax.plot(dp_list,y,label='Weighted Recall',color='cyan',marker='^',linestyle='--')\n",
    "ax.plot(dp_list,z,label='Accuracy',color='red',marker='^',linestyle='--') \n",
    " \n",
    "\n",
    "\n",
    "plt.title('')\n",
    "ax.set_xlabel('Demographic Disparity')\n",
    "ax.set_ylabel('Performance Metrics') \n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
