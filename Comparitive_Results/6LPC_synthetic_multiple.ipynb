{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def synthetic_svm(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0,probability=True)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "    d=svm.decision_function(X_test)\n",
    "    e=svm.predict_proba(X_test)\n",
    "    print(e)\n",
    "    print(d)\n",
    "    \n",
    "    \n",
    "           \n",
    "\n",
    "        \n",
    "    \n",
    "    return X_test,Y_test,Y_test_pred,e \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with accuracy\n",
    "def main(datax, y_test, y_test_pred): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = np.zeros((s, n), dtype = int)\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                data[j][i]= datax.iloc[j,i]\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"SVM----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"SVM accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    print(\"precision recall accuracy\")\n",
    "    \n",
    "\n",
    "    delta=1\n",
    "#     gama=[.1572]\n",
    "#     epsilon=[.0090]\n",
    "    epsilon=[.02,.04,.10,.15,.20,.30,.40,.50,.60]\n",
    "    gama=[.35]\n",
    "    \n",
    "#     epsilon=[.02,.04,.10,.15,.20,.30,.40,.50,.60]\n",
    "#     gama=[.30,.40,.50,.60,.70]\n",
    "#     epsilon=[.0090]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "#     for delta in delta1:\n",
    "    for gamma in gama:\n",
    "        for eps in epsilon:\n",
    "            u1,u2=min_max_lpc(data,gamma,eps,r2,delta)\n",
    "            #######################Disp_impact#######################  \n",
    "            print(\"gamma-epsilon-delta\",gamma,eps,delta)\n",
    "            accu_all=[]\n",
    "            DP_all=[]\n",
    "            precision_all=[]\n",
    "            recall_all=[]\n",
    "            acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "            count=0\n",
    "\n",
    "\n",
    "            for i in range(n):\n",
    "                 fi[i] = u1[i]\n",
    "            ar=[]\n",
    "\n",
    "            print(\"################################\")\n",
    "            \n",
    "            for j in range(s):\n",
    "                print(\"sensitive attribute \",(j+1)) \n",
    "                a=0\n",
    "                b=0\n",
    "                acc1=0\n",
    "                acc2=0\n",
    "                prec=0\n",
    "                reca=0\n",
    "                accur=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TP=0\n",
    "                TN=0\n",
    "                for i in range(n):\n",
    "                     if data[j][i]== 1 :\n",
    "                            a=a+1\n",
    "                            if fi[i]==1:\n",
    "                                acc1=acc1+1 \n",
    "                                if r[i]==1:\n",
    "                                    TP=TP+1\n",
    "                                else:\n",
    "                                     FP=FP+1                \n",
    "                            else:\n",
    "                                if r[i]==1:\n",
    "                                    FN=FN+1\n",
    "                                else:\n",
    "                                    TN=TN+1    \n",
    "\n",
    "                print(\"lp ############### prec reca accuracy for each sens\") \n",
    "                prec= float(TP/(TP+FP))\n",
    "                reca= float(TP/(TP+FN))\n",
    "                accur= float((TP+TN)/a)\n",
    "                print(prec,reca,accur)\n",
    "\n",
    "                print(\"By lp---------total , accepted, aceeptance rate:\")             \n",
    "\n",
    "                a1=float(acc1/a)\n",
    "                print(a,acc1,a1)\n",
    "                ar.append(a1)\n",
    "\n",
    "\n",
    "            maxi= max(ar)\n",
    "            mini= min(ar)\n",
    "            DP=float(maxi-mini)\n",
    "            print(\"data acceptance rates\")\n",
    "            print(ar)\n",
    "            print(\"data DP\")\n",
    "            print(DP) \n",
    "            TP=0\n",
    "            FP=0\n",
    "            FN=0\n",
    "            TN=0\n",
    "            accurr=0\n",
    "            precision=0\n",
    "            recall=0\n",
    "            for i in range(n):\n",
    "                    if fi[i]==1 and r[i]==1:\n",
    "                        TP=TP+1\n",
    "                    if fi[i]==-1 and r[i]==-1:\n",
    "                        TN=TN+1     \n",
    "                    if fi[i]==1 and r[i]==-1:\n",
    "                        FP=FP+1 \n",
    "                    if fi[i]==-1 and r[i]==1:\n",
    "                        FN=FN+1\n",
    "            print(\"total accepted \")            \n",
    "            precision=float(TP/(TP+FP))\n",
    "            print(\"finalprecision\",precision)\n",
    "            recall=float(TP/(TP+FN))\n",
    "            print(\"finalrecall\",recall)\n",
    "            accurr=float((TP+TN)/(TP+TN+FP+FN))\n",
    "            print(\"finalaccuracy\",accurr)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pulp as p \n",
    "def min_max_lpc(data1,gamma,eps,r,delta):\n",
    "    import pulp as p \n",
    "    \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMaximize)  \n",
    "   \n",
    "    \n",
    "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1               \n",
    "        sizes[i]=count\n",
    "  \n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "    \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')   \n",
    "        \n",
    "#     X[n]=  p.LpVariable(\"z1\",lowBound=0)\n",
    "    #X[n+1]=  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "\n",
    "    #########objective function#####################\n",
    "#     Lp_prob += X[n] \n",
    "            \n",
    "    Lp_prob += X[n]\n",
    "\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "#             Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) >= (2*gamma-1)*sizes[i]\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) <= ((2*gamma-1)+eps)*sizes[i]\n",
    "            \n",
    "      \n",
    " ##### without acc lpc###################        \n",
    "    #Lp_prob += p.lpSum([2*(X[i]-0.5)*r[i] for i in range(n)]) >= X[n]*n\n",
    "    #n is the number of elements in sensitive attribute \n",
    "                 \n",
    "#     Lp_prob += X[n] <= 42000\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    \n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data3 = make_classification(n_samples=8000, n_features=20, n_informative=10, n_redundant=10, n_repeated=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.00, class_sep=1.0, \n",
    "                            hypercube=True, shift=0.0, scale=1.0, shuffle=False, random_state=11)\n",
    "df3 = pd.DataFrame(data3[0],columns=['x'+str(i) for i in range(1,21)])\n",
    "df3['y'] = data3[1]\n",
    "# print(df3.head())\n",
    "\n",
    "data=df3.drop(columns=['y'])\n",
    "print(data)\n",
    "r=df3[['y']]\n",
    "print(r)\n",
    "\n",
    "\n",
    "\n",
    "X_test,Y_test,Y_test_pred,e = synthetic_svm(data , r)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(X_test)\n",
    "print(Y_test_pred)\n",
    "print(Y_test)\n",
    "# set_k=2\n",
    "p=5\n",
    "for set_k in np.arange(p,6,2):\n",
    "#for set_k in np.arange(2,11,2): \n",
    "    \n",
    "    sens=X_test[['x'+str(k) for k in range(1,set_k+1)]]\n",
    "#     print(set_k)\n",
    "#     print(sens)\n",
    "\n",
    "\n",
    "    p=sens.shape[0]\n",
    "    q=set_k\n",
    "    for i in range(0,p): \n",
    "        for j in range(0,set_k):  \n",
    "            if sens.iloc[i,j] > 0 :\n",
    "                       sens.iloc[i,j] = 1 \n",
    "            else: \n",
    "                       sens.iloc[i,j] = 0 \n",
    "#     print(sens)\n",
    "\n",
    "    sens1 = pd.get_dummies(sens, columns=['x'+str(k) for k in range(1,set_k+1)])\n",
    "    sensitive=sens1.T\n",
    "\n",
    "    print(sensitive)\n",
    "\n",
    "    # print(r.value_counts())\n",
    "    accu_all,DP_all,acceptance_rate,alpha_weight=main(sensitive, Y_test, Y_test_pred)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
