{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################Gerry mendering code on ADULT DATASET#######################\n",
    "\n",
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################LPCA######CODE##### same # beta setting ########\n",
    "               ### fixing alpha to 0 and (varying beta_avg) #########\n",
    "    # In {beta_avg config} all sub groups have different acceptance rate \n",
    "\n",
    "#data1 is sensitive group in binary matrix sets \n",
    "import time\n",
    "import pulp as p \n",
    "def min_sum_lpca(data1,beta_initial,eps,e,beta,alpha):\n",
    "#here beta_avg=beta, differnt beta[i]'s' is used for ranked weighting using Yang's configurations\n",
    "        \n",
    "    import pulp as p \n",
    "    import math\n",
    "    #for bilal\n",
    "    #beta=[beta1[1], beta1[0],beta1[6],beta1[4],beta1[3],beta1[2],beta1[5]]\n",
    "    #print(beta)\n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    \n",
    "   \n",
    "  \n",
    "    h1=[]\n",
    "    h2=[]\n",
    "    h3=[]\n",
    "    h4=[]\n",
    "    h5=[]\n",
    "    h6=[]\n",
    "    h7=[]\n",
    "    key1=[]\n",
    "    key2=[]\n",
    "    key3=[]\n",
    "    key4=[]\n",
    "    key5=[]\n",
    "    key6=[]\n",
    "    key7=[]\n",
    "    h8=[]\n",
    "    h9=[]\n",
    "    h10=[]\n",
    "    h11=[]\n",
    "    h12=[]\n",
    "    h13=[]\n",
    "    h14=[]\n",
    "    key8=[]\n",
    "    key9=[]\n",
    "    key10=[]\n",
    "    key11=[]\n",
    "    key12=[]\n",
    "    key13=[]\n",
    "    key14=[]\n",
    "    cost=np.zeros(n,dtype=int)\n",
    "    data2=np.zeros((m,n),dtype=int)\n",
    "    for i in range(n):\n",
    "        if data1[0][i]==1:            \n",
    "\n",
    "            h1.append(e[i][1])\n",
    "            key1.append(i)\n",
    "            \n",
    "\n",
    "        if data1[1][i]==1:\n",
    "            h2.append(e[i][1])\n",
    "            key2.append(i)\n",
    "            \n",
    "            \n",
    "        if data1[2][i]==1:\n",
    "            h3.append(e[i][1])\n",
    "            key3.append(i)\n",
    "            \n",
    "        if data1[3][i]==1:\n",
    "            h4.append(e[i][1])\n",
    "            key4.append(i)\n",
    "        if data1[4][i]==1:\n",
    "            h5.append(e[i][1])\n",
    "            key5.append(i)\n",
    "        if data1[5][i]==1:\n",
    "            h6.append(e[i][1])\n",
    "            key6.append(i)\n",
    "        if data1[6][i]==1:\n",
    "            h7.append(e[i][1])\n",
    "            key7.append(i)\n",
    "        if data1[7][i]==1:            \n",
    "            h8.append(e[i][1])\n",
    "            key8.append(i)\n",
    "        if data1[8][i]==1:\n",
    "            h9.append(e[i][1])\n",
    "            key9.append(i)\n",
    "            \n",
    "            \n",
    "        if data1[9][i]==1:\n",
    "            h10.append(e[i][1])\n",
    "            key10.append(i)\n",
    "            \n",
    "        if data1[10][i]==1:\n",
    "            h11.append(e[i][1])\n",
    "            key11.append(i)\n",
    "        if data1[11][i]==1:\n",
    "            h12.append(e[i][1])\n",
    "            key12.append(i)\n",
    "        if data1[12][i]==1:\n",
    "            h13.append(e[i][1])\n",
    "            key13.append(i)\n",
    "        \n",
    "#print(hc)\n",
    "#     print(key1)\n",
    "    \n",
    "    for i in range(1,len(h1)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h1[j-1]<h1[j]:\n",
    "                index=j\n",
    "                var=h1[j]\n",
    "                h1[j]=h1[j-1]\n",
    "                h1[j-1]=var\n",
    "\n",
    "                var2=key1[j]\n",
    "                key1[j]=key1[j-1]\n",
    "                key1[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "\n",
    "    for i in range(1,len(h2)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h2[j-1]<h2[j]:\n",
    "                index=j\n",
    "                var=h2[j]\n",
    "                h2[j]=h2[j-1]\n",
    "                h2[j-1]=var\n",
    "\n",
    "                var2=key2[j]\n",
    "                key2[j]=key2[j-1]\n",
    "                key2[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h3)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h3[j-1]<h3[j]:\n",
    "                index=j\n",
    "                var=h3[j]\n",
    "                h3[j]=h3[j-1]\n",
    "                h3[j-1]=var\n",
    "\n",
    "                var2=key3[j]\n",
    "                key3[j]=key3[j-1]\n",
    "                key3[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h4)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h4[j-1]<h4[j]:\n",
    "                index=j\n",
    "                var=h4[j]\n",
    "                h4[j]=h4[j-1]\n",
    "                h4[j-1]=var\n",
    "\n",
    "                var2=key4[j]\n",
    "                key4[j]=key4[j-1]\n",
    "                key4[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h5)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h5[j-1]<h5[j]:\n",
    "                index=j\n",
    "                var=h5[j]\n",
    "                h5[j]=h5[j-1]\n",
    "                h5[j-1]=var\n",
    "\n",
    "                var2=key5[j]\n",
    "                key5[j]=key5[j-1]\n",
    "                key5[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    for i in range(1,len(h6)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h6[j-1]<h6[j]:\n",
    "                index=j\n",
    "                var=h6[j]\n",
    "                h6[j]=h6[j-1]\n",
    "                h6[j-1]=var\n",
    "\n",
    "                var2=key6[j]\n",
    "                key6[j]=key6[j-1]\n",
    "                key6[j-1]=var2\n",
    "            else:\n",
    "                break        \n",
    "                \n",
    "\n",
    "    for i in range(1,len(h7)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h7[j-1]<h7[j]:\n",
    "                index=j\n",
    "                var=h7[j]\n",
    "                h7[j]=h7[j-1]\n",
    "                h7[j-1]=var\n",
    "\n",
    "                var2=key7[j]\n",
    "                key7[j]=key7[j-1]\n",
    "                key7[j-1]=var2\n",
    "            else:\n",
    "                break \n",
    "    ############################################            \n",
    "    for i in range(1,len(h8)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h8[j-1]<h8[j]:\n",
    "                index=j\n",
    "                var=h8[j]\n",
    "                h8[j]=h8[j-1]\n",
    "                h8[j-1]=var\n",
    "\n",
    "                var2=key8[j]\n",
    "                key8[j]=key8[j-1]\n",
    "                key8[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "\n",
    "    for i in range(1,len(h9)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h9[j-1]<h9[j]:\n",
    "                index=j\n",
    "                var=h9[j]\n",
    "                h9[j]=h9[j-1]\n",
    "                h9[j-1]=var\n",
    "\n",
    "                var2=key9[j]\n",
    "                key9[j]=key9[j-1]\n",
    "                key9[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h10)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h10[j-1]<h10[j]:\n",
    "                index=j\n",
    "                var=h10[j]\n",
    "                h10[j]=h10[j-1]\n",
    "                h10[j-1]=var\n",
    "\n",
    "                var2=key10[j]\n",
    "                key10[j]=key10[j-1]\n",
    "                key10[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h11)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h11[j-1]<h11[j]:\n",
    "                index=j\n",
    "                var=h11[j]\n",
    "                h11[j]=h11[j-1]\n",
    "                h11[j-1]=var\n",
    "\n",
    "                var2=key11[j]\n",
    "                key11[j]=key11[j-1]\n",
    "                key11[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "    for i in range(1,len(h12)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h12[j-1]<h12[j]:\n",
    "                index=j\n",
    "                var=h12[j]\n",
    "                h12[j]=h12[j-1]\n",
    "                h12[j-1]=var\n",
    "\n",
    "                var2=key12[j]\n",
    "                key12[j]=key12[j-1]\n",
    "                key12[j-1]=var2\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    for i in range(1,len(h13)):\n",
    "        for j in range(i,0,-1):\n",
    "            var=0\n",
    "            var2=0\n",
    "            if h13[j-1]<h13[j]:\n",
    "                index=j\n",
    "                var=h13[j]\n",
    "                h13[j]=h13[j-1]\n",
    "                h13[j-1]=var\n",
    "\n",
    "                var2=key13[j]\n",
    "                key13[j]=key13[j-1]\n",
    "                key13[j-1]=var2\n",
    "            else:\n",
    "                break        \n",
    "                \n",
    "\n",
    "\n",
    "    #######################################################################    \n",
    "    \n",
    "    ####################################################################### \n",
    "   \n",
    "    for j in range(len(key1)):    \n",
    "        data2[0][key1[j]]=(j+1)\n",
    "    for j in range(len(key2)):\n",
    "        data2[1][key2[j]]=(j+1)\n",
    "    \n",
    "    for j in range(len(key3)):\n",
    "        data2[2][key3[j]]=(j+1)\n",
    "                         \n",
    "        \n",
    "    for j in range(len(key4)):           \n",
    "        data2[3][key4[j]]=(j+1)\n",
    "                             \n",
    "    for j in range(len(key5)):\n",
    "        data2[4][key5[j]]=(j+1)\n",
    "       \n",
    "           \n",
    "    for j in range(len(key6)):                 \n",
    "        data2[5][key6[j]]=(j+1)\n",
    "    \n",
    "    for j in range(len(key7)):                 \n",
    "        data2[6][key7[j]]=(j+1)  \n",
    "       \n",
    "    for j in range(len(key8)):    \n",
    "        data2[7][key8[j]]=(j+1)\n",
    "    for j in range(len(key9)):\n",
    "        data2[8][key9[j]]=(j+1)\n",
    "    \n",
    "    for j in range(len(key10)):\n",
    "        data2[9][key10[j]]=(j+1)\n",
    "                         \n",
    "        \n",
    "    for j in range(len(key11)):           \n",
    "        data2[10][key11[j]]=(j+1)\n",
    "                             \n",
    "    for j in range(len(key12)):\n",
    "        data2[11][key12[j]]=(j+1)\n",
    "       \n",
    "           \n",
    "    for j in range(len(key13)):                 \n",
    "        data2[12][key13[j]]=(j+1)\n",
    "    \n",
    "#sum up the weighted subgroup rank in cost        \n",
    "    for j in range(n):\n",
    "        summ=0\n",
    "        for i in range(m):\n",
    "       \n",
    "            summ=summ+data2[i][j] \n",
    "        cost[j]=summ\n",
    "        \n",
    "        \n",
    "    ################\n",
    "    \n",
    "    \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    ###############################Optimization fuction for LPCA###################\n",
    "# beta_avg(Yang's to achieve least DP at alpha=0  ) \n",
    "# beta_initial (acceptance rate) config obtaind for each group from random forest prediction)   \n",
    "\n",
    "\n",
    "    X=np.zeros(n+m+1,dtype=p.LpVariable)\n",
    "    Y=np.zeros(m,dtype=p.LpVariable)\n",
    "    \n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "  \n",
    "    max_size=0\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1 \n",
    "        if count>max_size:\n",
    "            max_size=count\n",
    "        sizes[i]=count\n",
    "    print(sizes)        \n",
    "    \n",
    " ################ As all beta[i]'s are different so beta_avg=beta #################   \n",
    "    \n",
    "    beta_avg=beta\n",
    "    \n",
    "    \n",
    "    \n",
    "    select_sizes=np.zeros(m,dtype=int)\n",
    "   \n",
    "    size_final=np.zeros(m,dtype=int)\n",
    "\n",
    "    for i in range(m):\n",
    "        var1 = str(n+100+i)\n",
    "        Y[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Continuous')\n",
    "    \n",
    "    for i in range(n):\n",
    "        var1=str(i)       \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "   \n",
    "    X[n]=p.LpVariable(str(n),lowBound=0,upBound=1,cat='Continuous')  \n",
    "#minimize Objective#\n",
    "    Lp_prob+= p.lpSum([(X[j])*cost[j] for j in range(n)])\n",
    "    \n",
    "\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) >= (Y[i]-eps)*sizes[i]\n",
    "            Lp_prob += p.lpSum([(X[j])*(data1[i][j]) for j in range(n)]) <= (Y[i]+eps)*sizes[i]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "# for minimum ddp at alpa=0 setup (like paper) change (1- alpha) to (alpha) & (alpha) to (1-alpha)    \n",
    "    for i in range(m):\n",
    "            if beta_initial[i] >= beta_avg:\n",
    "\n",
    "                Lp_prob += Y[i] >= (1-alpha)*beta_initial[i] +alpha*beta_avg\n",
    "                Lp_prob += Y[i] <= (1-alpha)*beta_initial[i] +alpha*beta_avg\n",
    "               \n",
    "            else:\n",
    "                Lp_prob += Y[i] >= (1-alpha)*beta_initial[i] + alpha*beta_avg\n",
    "                Lp_prob += Y[i] <= beta_avg   \n",
    "    '''      \n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "        Lp_prob += Y[i] >= (alpha)*beta_initial[i] +(1-alpha)*beta_avg[i]\n",
    "        Lp_prob += Y[i] <= (alpha)*beta_initial[i] +(1-alpha)*beta_avg[i]\n",
    "                         \n",
    "   \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"objective is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    print(\"discripency is:\") \n",
    "    print(p.value(X[n]))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "#             if(data1[2][i]==1):\n",
    "#                 print(\"no\")\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LPCA for Gerrymendering Groups\n",
    "def main(datax, y_test, y_test_pred,e): \n",
    "        \n",
    "    n=datax.shape[1]\n",
    "    s=datax.shape[0]    \n",
    "    data = datax\n",
    "    \n",
    "    r = np.zeros(n, dtype = int) \n",
    "    \n",
    "    for i in range(n):\n",
    "        if int(y_test.iloc[i])==1 :\n",
    "            r[i]=1\n",
    "        else :\n",
    "            r[i]= -1  \n",
    "    \n",
    "    r2 = np.zeros(n, dtype = int) \n",
    "    for i in range(n):\n",
    "        if int(y_test_pred[i])==1 :\n",
    "            r2[i]=1\n",
    "        else :\n",
    "            r2[i]= -1          \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        for i in range(n):\n",
    "                if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r[i]==1:\n",
    "                         acc1=acc1+1 \n",
    "\n",
    "        print(\"ACTUAL----------total ,accepted, aceeptance rate:\")             \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "        \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP)\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for j in range(s):\n",
    "        print(\"sensitive attribute \",(j+1)) \n",
    "        a=0\n",
    "        b=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        prec=0\n",
    "        reca=0\n",
    "        accur=0\n",
    "        FP=0\n",
    "        FN=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        for i in range(n):\n",
    "             if data[j][i]== 1 :\n",
    "                    a=a+1\n",
    "                    if r2[i]==1:\n",
    "                        acc1=acc1+1 \n",
    "                        if r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        else:\n",
    "                             FP=FP+1                \n",
    "                    else:\n",
    "                        if r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        else:\n",
    "                            TN=TN+1    \n",
    "        \n",
    "        print(\"prec reca accuracy for each sens\") \n",
    "        prec= float(TP/(TP+FP))\n",
    "        reca= float(TP/(TP+FN))\n",
    "        accur= float((TP+TN)/a)\n",
    "        print(prec,reca,accur)\n",
    "        \n",
    "        print(\"RandomForest----------total , accepted, aceeptance rate:\")             \n",
    "        \n",
    "        a1=float(acc1/a)\n",
    "        print(a)\n",
    "        \n",
    "        print(acc1)\n",
    "        print(a1)\n",
    "        ar.append(a1)\n",
    "    \n",
    " #COMMENT   : \"ar\" #############use this predicted RandomForet accptance rate(config) hardcoded or\n",
    "#can pass it through LPCA as lpca() \n",
    "#above ar: Random forest acceptance rate is use as beta_initial/beta (named as beata_initial in paper)\n",
    "######################################RF acceptance rate as beta_initial #############   \n",
    "    beta_initial=ar\n",
    "\n",
    "########################################################################################    \n",
    " \n",
    "    maxi= max(ar)\n",
    "    mini= min(ar)\n",
    "    DP=float(maxi-mini)\n",
    "    print(\"data acceptance rates\")\n",
    "    print(ar)\n",
    "    print(\"data DP\")\n",
    "    print(DP) \n",
    "    \n",
    "    print(\"Random Forest accuracy--------------------------\")\n",
    "    prec=0\n",
    "    reca=0\n",
    "    accur=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(n):\n",
    "            if r2[i]==1:\n",
    "                acc1=acc1+1 \n",
    "                if r[i]==1:\n",
    "                    TP=TP+1\n",
    "                else:\n",
    "                     FP=FP+1                \n",
    "            else:\n",
    "                if r[i]==1:\n",
    "                     FN=FN+1\n",
    "                else:\n",
    "                     TN=TN+1    \n",
    "\n",
    "        \n",
    "    prec= float(TP/(TP+FP))\n",
    "    reca= float(TP/(TP+FN))\n",
    "    accur= float((TP+TN)/n)\n",
    "    print(prec,reca,accur)\n",
    "    \n",
    "\n",
    "\n",
    "    epsilon=[.005,.01]\n",
    "    fi= np.zeros(n,dtype=int) \n",
    "\n",
    "    #alpha=[ 9211,  4356, 11678,  1220,   404,   150 ,  115]\n",
    "    a=0\n",
    "    \n",
    "    gamma=[[0.10295915871851308, 0.16058394160583941, 0.10927152317880795, 0.10742857142857143, 0.1, 0.09740259740259741, 0.10389751384214527, 0.1049127640036731, 0.10429868128104128, 0.14108910891089108, 0.10327868852459017, 0.034782608695652174, 0.06],\n",
    "[0.10381511371973588, 0.16058394160583941, 0.10596026490066225, 0.10657142857142857, 0.08461538461538462, 0.0762987012987013, 0.10454890891325588, 0.10078053259871442, 0.10464120568590513, 0.13613861386138615, 0.09098360655737706, 0.043478260869565216, 0.06],\n",
    " [0.10552702372218146, 0.16423357664233576, 0.09602649006622517, 0.10542857142857143, 0.07692307692307693, 0.06493506493506493, 0.10552600151992184, 0.0980257116620753, 0.10549751669806473, 0.13613861386138615, 0.08032786885245902, 0.043478260869565216, 0.06],\n",
    "[0.10149180728784545, 0.14963503649635038, 0.11920529801324503, 0.11, 0.1, 0.11363636363636363, 0.10302898708066442, 0.10973370064279155, 0.10404178797739339, 0.13366336633663367, 0.11639344262295082, 0.05217391304347826, 0.06666666666666667]]\n",
    "    '''\n",
    "    k=[0,2,1,3,5,4,6,7,8,10,9,12,11]\n",
    "    gamma=np.zeros((4,13),dtype=float)\n",
    "    for j in range(13):\n",
    "        for i in range(4):\n",
    "            gamma[i][j]=gamma2[i][k[j]]\n",
    "    '''        \n",
    "    \n",
    "    alpha=[0]\n",
    "    t=0\n",
    "    \n",
    "    beta_converge=gamma\n",
    "    \n",
    "    \n",
    " \n",
    "    a=0\n",
    "    #for t in range(gamma.shape[0]):\n",
    "    #for t in range(28):\n",
    "    for eps in epsilon:\n",
    "        for new in range(4):\n",
    "        \n",
    "            for a in alpha:\n",
    "                k=0\n",
    "                u1,u2=min_sum_lpca(data,beta_initial,eps,e,gamma[new],a)\n",
    "                #######################Disp_impact#######################  \n",
    "                print(\"gamma-epsilon-delta\",gamma[new],eps)\n",
    "                accu_all=[]\n",
    "                DP_all=[]\n",
    "                precision_all=[]\n",
    "                recall_all=[]\n",
    "                ar_all=[]\n",
    "                acceptance_rate=np.zeros((7,28),dtype=float)\n",
    "                count=0\n",
    "                print(\"<--------------------------------------->\")\n",
    "                print(\"iteration t\",k)\n",
    "                k=k+1\n",
    "\n",
    "\n",
    "                for i in range(n):\n",
    "                     fi[i] = u1[i]\n",
    "\n",
    "\n",
    "                for j in range(s):\n",
    "                    print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "                    TP=0\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TN=0\n",
    "                    precision=0\n",
    "                    recall=0\n",
    "                    for i in range(n):\n",
    "                         if data[j][i]== 1 :                        \n",
    "                            if fi[i]==1 and r[i]==1:\n",
    "                                TP=TP+1\n",
    "                            if fi[i]==1 and r[i]==-1:\n",
    "                                FP=FP+1 \n",
    "                            if fi[i]==-1 and r[i]==1:\n",
    "                                FN=FN+1\n",
    "                            if fi[i]==-1 and r[i]==-1:\n",
    "                                TN=TN+1    \n",
    "                    if TP+FP !=0:\n",
    "                        precision=float(TP/(TP+FP))\n",
    "                    #print(\"precision\",precision)\n",
    "                    if TP+FN !=0:    \n",
    "                        recall=float(TP/(TP+FN))\n",
    "                    #print(\"recall\",recall)\n",
    "\n",
    "                    precision_all.append(precision)\n",
    "                    recall_all.append(recall)\n",
    "                    #print(\"TP,FP,TN,FN\")\n",
    "                    #print(TP,FP,TN,FN)\n",
    "\n",
    "                    a=0\n",
    "                    b=0\n",
    "                    acc1=0\n",
    "                    acc2=0\n",
    "                    for i in range(n):\n",
    "                            if data[j][i]== 1 :\n",
    "                                a=a+1\n",
    "                                if fi[i]==1:\n",
    "                                     acc1=acc1+1 \n",
    "\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                    a1=float(acc1/a)\n",
    "\n",
    "\n",
    "\n",
    "        #                         print(a)\n",
    "        #                         print(acc1)\n",
    "        #                         print(a1)\n",
    "                    ar_all.append(a1)\n",
    "\n",
    "                count = count+1\n",
    "                maxi=max(ar_all)\n",
    "                mini= min(ar_all)\n",
    "                DP=float(maxi-mini)\n",
    "                print(\"individual acceptance rates\")\n",
    "                print(ar_all)\n",
    "                print(\"individul precision\")\n",
    "                print(precision_all)\n",
    "                print(\"individual recall\")\n",
    "                print(recall_all)\n",
    "                print(\"DP all\")\n",
    "                print(DP)\n",
    "                f_acc=0\n",
    "                for i in range(n):\n",
    "                     if fi[i] == r[i]:\n",
    "                            f_acc=f_acc+1\n",
    "                f_acc_l=float((f_acc*100)/n) \n",
    "\n",
    "        #######################################################################33   \n",
    "\n",
    "        #                         print(\"sensitive attribute \",(j+1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                TP=0\n",
    "                FP=0\n",
    "                FN=0\n",
    "                TN=0\n",
    "                precision=0\n",
    "                recall=0\n",
    "                accu=0\n",
    "                for i in range(n):\n",
    "                        if fi[i]==1 and r[i]==1:\n",
    "                            TP=TP+1\n",
    "                        if fi[i]==1 and r[i]==-1:\n",
    "                            FP=FP+1 \n",
    "                        if fi[i]==-1 and r[i]==1:\n",
    "                            FN=FN+1\n",
    "                        if fi[i]==-1 and r[i]==-1:\n",
    "                            TN=TN+1    \n",
    "\n",
    "                if TP+FP!=0:\n",
    "                    precision=float(TP/(TP+FP))\n",
    "                print(\"precision all\",precision)\n",
    "                if TP+FN!=0:\n",
    "                    recall=float(TP/(TP+FN))\n",
    "\n",
    "\n",
    "                print(\"recall all\",recall)\n",
    "                accu=float((TP+TN)/(TP+FN+TN+FP))\n",
    "\n",
    "\n",
    "                print(\"accuracy all\",accu)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"TP,FP,TN,FN\")\n",
    "                print(TP,FP,TN,FN)\n",
    "        #                         print(\"total ,fair accepted, aceeptance rate:\")             \n",
    "                a1=float(acc1/a)\n",
    "\n",
    "\n",
    "    print(\"<--------------------------------------->\")\n",
    "    alpha_weight=np.arange(0,1.05,.05)        \n",
    "    return accu_all,DP_all,acceptance_rate,alpha_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def adult_rf(X,Y):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0,shuffle=True) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    \n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=64, random_state=0)\n",
    "    \n",
    "    print(Y_train.dtypes)\n",
    "    Y_train=Y_train.astype('int')\n",
    "    print(Y_train.dtypes)\n",
    "    \n",
    "    print(Y_test.dtypes)\n",
    "    Y_test=Y_test.astype('int')\n",
    "    print(Y_test.dtypes)\n",
    "    \n",
    "    \n",
    "    rf.fit(X_train, Y_train)\n",
    "    print('The accuracy of the RF classifier on training data is {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "    print('The accuracy of the RF classifier on test data is {:.2f}'.format(rf.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=rf.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=rf.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    e=rf.predict_proba(X_test)\n",
    "    print(e)\n",
    "    return X_test,Y_test_pred,Y_test,e\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without accuracy\n",
    "import time\n",
    "# import pulp as p \n",
    "# from random import *\n",
    "\n",
    "# Add column names to data set\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Read in train data\n",
    "adult_train = pd.read_csv('data/adult_actual/adult_train_data.csv', header=None, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_train = adult_train.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Read in test data\n",
    "adult_test = pd.read_csv('data/adult_actual/adult_test_data.csv', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_test = adult_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Remove '.' in income column\n",
    "adult_test['income'] = adult_test['income'].apply(lambda x: '>50k' if x=='>50k.'  else '<=50k')\n",
    "\n",
    "\n",
    "# Convert '?' to NaNs and remove the entries with NaN value\n",
    "# Check missing value code and convert to NaNs\n",
    "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in object_col:\n",
    "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
    "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
    "\n",
    "# Perform an mssing assessment in each column of the dataset.\n",
    "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
    "col_missing_pct.sort_values(ascending=False)\n",
    "\n",
    "# Remove data entries with missing value\n",
    "adult_train = adult_train.dropna(axis=0, how='any')\n",
    "adult_test = adult_test.dropna(axis=0, how='any')\n",
    "\n",
    "# Show the results of the split\n",
    "# print(\"After removing the missing value:\")\n",
    "# print(\"Training set has {} samples.\".format(adult_train.shape[0]))\n",
    "# print(\"Testing set has {} samples.\".format(adult_test.shape[0]))\n",
    "for col in object_col:\n",
    "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')\n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())    \n",
    "\n",
    "adult_train.reset_index(drop=True, inplace=True)\n",
    "adult_test.reset_index(drop=True, inplace=True)\n",
    "p=adult_train.shape[0]\n",
    "q =adult_test.shape[0]\n",
    "# reducing dimensionality of some very sparse features\n",
    "for i in range(0,p):\n",
    "    if adult_train.loc[i,'native-country'] not in [\"united-states\"] :\n",
    "               adult_train.loc[i,\"native-country\"] = \"non-united-stated\"        \n",
    "    if adult_train.loc[i,\"education\"] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"prim-middle-school\"\n",
    "    elif adult_train.loc[i,\"education\"] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"high-school\"   \n",
    "    if adult_train.loc[i,'income'] in [\">50k\"] :\n",
    "               adult_train.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_train.loc[i,\"income\"] = 0         \n",
    "#reducing dimensionality of some very sparse features\n",
    "for i in range(0,q):                \n",
    "    if adult_test.loc[i,'native-country'] not in [\"united-states\"]:\n",
    "               adult_test.loc[i,'native-country'] = \"non-united-stated\"\n",
    "    if adult_test.loc[i,'education'] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_test.loc[i,'education'] = \"prim-middle-school\"\n",
    "    elif adult_test.loc[i,'education'] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_test.loc[i,'education'] = \"high-school\"   \n",
    "    if adult_test.loc[i,'income'] in [\">50k\",\">50k.\"] :\n",
    "               adult_test.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_test.loc[i,\"income\"] = 0            \n",
    "# print(adult_train.head())\n",
    "# print(adult_test.head())\n",
    "DATA=pd.concat([adult_train,adult_test],ignore_index=True)\n",
    "# print(DATA.tail())\n",
    "m=DATA.shape[1]\n",
    "\n",
    "dat=DATA.iloc[:,0:m-1]\n",
    "\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "num_col = dat.dtypes[dat.dtypes != 'object'].index\n",
    "features_log_minmax_transform = pd.DataFrame(data = dat)\n",
    "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
    "\n",
    "display(features_log_minmax_transform.head())\n",
    "\n",
    "# sens=DATA[['sex','race']]\n",
    "\n",
    "Data_c = pd.get_dummies(features_log_minmax_transform, columns=['sex','race','workclass','education','marital-status','occupation','relationship','native-country'], prefix =['s','r','work','edu','ms','occ','rls','nc'])\n",
    "r=DATA.iloc[:,m-1]\n",
    "print(Data_c)\n",
    "print(DATA['income'].value_counts())\n",
    "#marital\n",
    "#U=80, M=24928, S=11568, D=4612\n",
    "# m_3, m_0, m_1, m_2\n",
    "#age\n",
    "#>60 and <25= a_1\n",
    "#>=25and <=60 =a_2\n",
    "# print(data.head())\n",
    "# print(data.shape[0],data.shape[1])\n",
    "\n",
    "#sensitive columns name 0='age',2='marital'\n",
    "\n",
    "\n",
    "X_test,Y_test_pred,Y_test,e = adult_rf(Data_c , r)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "# Y_test_pred.reset_index()\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(X_test)\n",
    "# print(Y_test_pred)\n",
    "# print(Y_test)\n",
    "sens=X_test[['s_male', 's_female'  ,'r_white', 'r_black', 'r_asian-pac-islander','r_amer-indian-eskimo','r_other']]\n",
    "\n",
    "sensitive = sens.T\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive2=sens.values\n",
    "\n",
    "sensitive1 = np.zeros((sensitive2.shape[0],10),dtype=float)\n",
    "#sensitive2 = np.zeros((sens.shape[0],7),dtype=int)\n",
    "sensitive3 = np.zeros((sensitive2.shape[0],17),dtype=float)\n",
    "\n",
    "   #print(sensitive1.shape[0])\n",
    "   #print(sensitive1.shape[1])\n",
    "\n",
    "'''\n",
    "for k in range(sens.shape[0]):\n",
    "    for i in range(7):\n",
    "        sensitive2[k][i] = sens.iloc[k,i]\n",
    "'''\n",
    "for k in range(sensitive2.shape[0]):\n",
    "    count = 0\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            if sensitive2[k][i]==1 and sensitive2[k][2+j]==1:\n",
    "                sensitive1[k][count] = 1\n",
    "                count = count+1\n",
    "            else:\n",
    "                sensitive1[k][count] = 0\n",
    "                count = count+1\n",
    "                \n",
    "selected = []          \n",
    "counts = []\n",
    "sensitive3 = np.concatenate((sensitive1,sensitive2), axis = 1)   \n",
    "sens2=sensitive3[:,[0, 1, 2, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16]]\n",
    "sensitive1=np.transpose(sens2)\n",
    "\n",
    "sensitiven=np.zeros((13,sensitive1.shape[1]),dtype=int)\n",
    "k=[0,2,1,3,5,4,6,7,8,10,9,12,11]\n",
    "for i in range(13):\n",
    "    sensitiven[i,:]=sensitive1[k[i],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yang gerry new\n",
    "accu_all,DP_all,acceptance_rate,alpha_weight = main(sensitiven, Y_test, Y_test_pred,e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "labels = ['0.0974','0.1171','0.1207','0.1258']\n",
    "men_means = [0.827, .83187 ,.8315 ,.8304]\n",
    "women_means = [ 0.7869,0.7890469521633375,0.7900051595783887,0.788309869536375]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, color = 'g',label='LPCA ')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, color = 'blue',label='Yang ')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_xlabel('Demographic Disparity')\n",
    "ax.set_title('ADULT')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "#ax.legend()\n",
    "ax.set_ylim(.5,.85 )\n",
    "#ax.bar_label(rects1, padding=3)\n",
    "#ax.bar_label(rects2, padding=3)\n",
    "\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.30), shadow=True, ncol=10)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('a5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
